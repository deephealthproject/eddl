### Development Status

| Image | Meaning |
| ------------- |------|
| âœ… | Done |
| ğŸ”µ | In progress |
| âŒ | Todo |


# Layers
---

## Core layers

| Functionality | CPU | GPU | ONNX | Comments |
| ------------- |------| -----|------|---------|
| Dense | âœ… | âœ… | âœ… | Just your regular densely-connected NN layer. |
| Dropout | âœ… | âœ… | âœ… | Applies Dropout to the input. |
| Flatten | âœ… | âœ… | âœ… | Flattens the input. Does not affect the batch size. (Wrapper for Reshape) |
| Input | âœ… | âœ… | âœ… | Used to instantiate a EDDL tensor. |
| Reshape | âœ… | âœ… | âœ… | Reshapes an output to a certain shape. |
| Permute | âœ… | âœ… | âŒ | Permutes the dimensions of the input according to a given pattern. |
| Embedding | âŒ | âŒ | âŒ | Turns positive integers (indexes) into dense vectors of fixed size; (also known as mapping). e.g. `[[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]` |
| Transpose | âœ… | âœ… | âŒ | Permute the last two dimensions |


## Activations

| Functionality | CPU | GPU | ONNX | Comments |
| ------------- |------| -----|------| ---------|
| ELU | âœ… | âœ… | âŒ | Exponential linear unit. |
| Exponential |  âœ… | âœ… | âŒ | Exponential (base e) activation function. |
| HardSigmoid | âœ… | âœ… | âŒ | Hard sigmoid activation function. |
| LeakyReLu | âœ… | âœ… | âŒ | Leaky version of a Rectified Linear Unit.  |
| Linear | âœ… | âœ… | âŒ | Linear (i.e. identity) activation function.  |
| PReLU | âŒ | âŒ | âŒ | Parametric Rectified Linear Unit.   |
| ReLu | âœ… | âœ… | âœ… | Rectified Linear Unit. |
| Softmax | âœ… | âœ… | âœ… | Softmax activation function. |
| Selu |  âœ… | âœ… | âŒ | Scaled Exponential Linear Unit (SELU). |
| Sigmoid | âœ… | âœ… | âŒ | Sigmoid activation function. |
| Softplus | âœ… | âœ… | âŒ | Softplus activation function. |
| Softsign | âœ… | âœ… | âŒ | Softsign activation function. |
| Tanh | âœ… | âœ… | âŒ | Hyperbolic tangent activation function. |
| ThresholdedReLU | âœ… | âœ… | âŒ | Thresholded Rectified Linear Unit. |


## Convolutional layers

| Functionality | CPU | GPU | ONNX | Comments |
| ------------- |------| -----| ------|---------|
| Conv2D | âœ… | âœ… | âœ… | 2D convolution. |
| Conv2DT | âŒ | âŒ | âŒ | Transposed convolution |
| UpSampling | âœ… | âœ… | âŒ | Practically the same as `Scale(mode="nearest")`. Instead of performing nearest interpolation, this works by repeating n times the elements of each axis `[2, 1] => [2, 2, 1, 1]`. |


## Data transformation/augmentation

### Data transformations

Deterministic transformations

| Functionality | CPU | GPU | ONNX | Comments |
| ------------- |------| -----| ------|---------|
| Affine | âŒ | âŒ | âŒ | Affine transformation of the image keeping center invariant: rotate+translate+scale+shear |
| Crop | âœ… | âœ… | âŒ | Crops the given image at `[(top, left), (bottom, right)]` |
| CenteredCrop | âœ… | âœ… | âŒ | Crops the given image at the center with size (width, height)  |
| ColorJitter | âŒ | âŒ | âŒ | Randomly change the brightness, contrast and saturation of an image. |
| CropScale | âœ… | âœ… | âŒ | Crop the given image at `[(top, left), (bottom, right)]` and scale it to the parent size |
| Cutout | âœ… | âœ… | âŒ | Selects a rectangle region in an image at `[(top, left), (bottom, right)]` and erases its pixels using a constant value. |
| Flip | âœ… | âœ… | âŒ | Flip the given image at `axis=n`. |
| Grayscale | âŒ | âŒ | âŒ | Convert image to grayscale. |
| HorizontalFlip | âœ… | âœ… | âŒ | Horizontally flip the given image. |
| Pad | âŒ | âŒ | âŒ | Pad the given image on all sides with the given "pad" value. |
| Rotate | âœ… | âœ… | âŒ | Rotate the image by angle. |
| Scale | âœ… | âœ… | âŒ | Resize the input image to the given size. `[height, width]` |
| Shift | âœ… | âœ… | âŒ | Shift the input image `[a, b]` |
| VerticallyFlip | âœ… | âœ… | âŒ | Vertically flip the given image. |
| Normalize | âŒ | âŒ | âŒ | Normalize an image with mean and standard deviation. |


### Data augmentations

Apply data transformations with random parametrization.

| Functionality | CPU | GPU | ONNX | Comments |
| ------------- |------| -----| ------|---------|
| RandomAffine | âŒ | âŒ | âŒ | Random affine transformation of the image keeping center invariant: rotate+translate+scale+shear |
| RandomCrop | âœ… | âœ… | âŒ | Crop the given image at a random location with size `[height, width]`  |
| RandomCropScale | âœ… | âœ… | âŒ | Crop the given image randomly by the size in a range `[a, b]` by and scale it to the parent size |
| RandomCutout | âœ… | âœ… | âŒ | Randomly selects a rectangle region in an image and erases its pixels. The random region is defined by the range `[(min_x, max_x), (min_y, max_y)]`, where these are relative values |
| RandomFlip | âœ… | âœ… | âŒ | Flip the given image at `axis=n` randomly with a given probability. |
| RandomGrayscale | âŒ | âŒ | âŒ | Randomly convert image to grayscale with a probability of p (default 0.1). |
| RandomHorizontalFlip | âœ… | âœ… | âŒ | Horizontally flip the given image randomly with a given probability. |
| RandomRotation | âœ… | âœ… | âŒ | Rotate the image randomly by an angle defined in a range `[a, b]`. |
| RandomScale | âœ… | âœ… | âŒ | Resize the input image randomly by the size in a range `[a, b]` |
| RandomShift | âœ… | âœ… | âŒ | Shift the input image randomly in range `[a, b]` |
| RandomVerticalFlip | âœ… | âœ… | âŒ | Vertically flip the given image randomly with a given probability. |


## Merge layers

| Functionality | CPU | GPU | ONNX | Comments |
| ------------- |------| -----| ------|---------|
| Add | âœ… | âœ… | âŒ | Layer that adds a list of inputs. |
| Average | âœ… | âœ… | âŒ | Layer that averages a list of inputs. |
| Concatenate | âœ… | âœ… | âœ… | Layer that concatenates a list of inputs. |
| Dot |  âŒ | âŒ | âŒ | Layer that computes a dot product between samples in two tensors.  |
| Multiply | âœ… | âœ… | âŒ | Layer that multiplies (element-wise) a list of inputs. |
| Maximum | âœ… | âœ… | âŒ | Layer that computes the maximum (element-wise) a list of inputs. |
| Minimum | âœ… | âœ… | âŒ | Layer that computes the minimum (element-wise) a list of inputs. |
| Substract | âœ… | âœ… | âŒ | Layer that subtracts two inputs. |


## Normalization

| Functionality | CPU | GPU | ONNX | Comments |
| ------------- |------| -----| ------|---------|
| BatchNorm | âœ… | âœ… | âœ… | Batch normalization layer (Ioffe and Szegedy, 2014).  |
| LayerNormalization | âœ… | âœ… | âŒ | Layer normalization layer (Ba et al., 2016)  |
| GroupNormalization | âœ… | âœ… | âŒ | Group normalization layer (Yuxin Wu and Kaiming He, 2018).  |
| Norm | âœ… | âœ… | âŒ |   |
| NormMax | âœ… | âœ… | âŒ |   |
| NormMinMax | âœ… | âœ… | âŒ |   |


## Noise layers

| Functionality | CPU | GPU | ONNX | Comments |
| ------------- |------| -----| ------|---------|
| GaussianNoise | âœ… | âœ… | âŒ | Apply additive zero-centered Gaussian noise. |
| UniformNoise | âœ… | âœ… | âŒ | Apply additive zero-centered uniform noise.


## Pooling layers

| Functionality | CPU | GPU | ONNX | Comments |
| ------------- |------| -----| ------|---------|
| AvgPool | âŒ | âŒ | âœ… | Average max pooling operation |
| GlobalMaxPool | âœ… | âœ… | âŒ | Global max pooling operation |
| GlobalAveragePool | âŒ | âŒ | âŒ | Global average pooling operation |
| MaxPool | âœ… | âœ… | âœ… | Max pooling operation |


## Operators layers

| Functionality | CPU | GPU | ONNX | Comments |
| ------------- |------| -----| ------|---------|
| Abs |  âœ… | âœ… | âŒ | |
| Diff | âœ… | âœ… | âŒ | |
| Div | âœ… | âœ… | âŒ | |
| Exp | âœ… | âœ… | âŒ | |
| Log | âœ… | âœ… | âŒ | |
| Log2 |  âœ… | âœ… | âŒ | |
| Log10 | âœ… | âœ… | âŒ | |
| Mult | âœ… | âœ…| âŒ | |
| Pow |  âœ… | âœ… | âŒ | |
| Select |  âœ… | âœ… | âŒ | |
| Sqrt |  âœ… | âœ… | âŒ | |
| Sum | âœ… | âœ… | âŒ | |


## Reduction layers

| Functionality | CPU | GPU | ONNX | Comments |
| ------------- |------| -----| ------|---------|
| Max | âœ…| âœ… | âŒ | |
| Mean | âœ…| âœ… | âŒ | |
| Min | âœ…| âœ… | âŒ | |
| Sum | âœ…| âœ… | âŒ | |
| Var | âœ…| âœ… | âŒ | |


## Recurrent layers

| Functionality | CPU | GPU | ONNX | Comments |
| ------------- |------| -----| ------|---------|
| GRU | âŒ | âŒ | âŒ | Gated Recurrent Unit - Cho et al. 2014. |
| LSTM | âŒ | âŒ | âŒ | Long Short-Term Memory layer - Hochreiter 1997. |
| RNN | âŒ | âŒ | âŒ | Fully-connected RNN where the output is to be fed back to input. |


## Regularizer layers

| Functionality | CPU | GPU | ONNX | Comments |
| ------------- |------| -----| ------|---------|
| L1 | âœ… | âœ… | âŒ | Lasso Regression |
| L2 | âœ… | âœ… | âŒ | Ridge Regression |
| L1L2 | âœ… | âœ… | âŒ |  |


# Initializers

| Functionality | CPU | GPU | Comments |
| ------------- |------| -----|---------|
| Constant | âœ… | âœ… | Initializer that generates tensors initialized to a constant value |
| GlorotNormal | âœ… | âœ… | Glorot normal initializer, also called Xavier normal initializer. |
| GlorotUniform | âœ… | âœ… | Glorot uniform initializer, also called Xavier uniform initializer. |
| HeNormal | âŒ | âŒ | _He_ normal initializer. |
| HeUniform | âŒ | âŒ | _He_ uniform initializer. |
| Identity | âŒ | âŒ | Initializer that generates the identity matrix. |
| LeCunUniform | âŒ | âŒ | LeCun uniform initializer. |
| LeCunNormal | âŒ | âŒ | LeCun normal initializer. |
| Orthogonal | âŒ | âŒ | Initializer that generates a random orthogonal matrix.  |
| RandomNormal |  âœ… | âœ… | Initializer that generates tensors with a normal distribution. |
| RandomUniform |  âœ… | âœ… | Initializer that generates tensors with a uniform distribution.  |
| TruncatedNormal | âœ… | âœ…  | Initializer that generates a truncated normal distribution.  |
| VarianceScaling |  âŒ | âŒ | Initializer capable of adapting its scale to the shape of weights.  |


# Constraints

| Functionality | CPU | GPU | Comments |
| ------------- |------| -----|---------|
| MaxNorm |  âŒ | âŒ | MaxNorm weight constraint. |
| MinMaxNorm |  âŒ | âŒ | MinMaxNorm weight constraint. |
| NonNeg |  âŒ | âŒ | Constrains the weights to be non-negative.  |
| UnitNorm |  âŒ | âŒ | Constrains the weights incident to each hidden unit to have unit norm. |


# Loss functions

| Functionality | CPU | GPU | Comments |
| ------------- |------| -----|---------|
| CrossEntropy | âœ… | âœ… | Categorical Cross-Entropy Error |
| MSE | âœ… | âœ… | Mean Squared Error |
| MAE | âŒ | âŒ | Mean Absolute Error  |
| MRE | âŒ | âŒ | Mean Relative Error |
| MSLE | âŒ | âŒ | Mean Squared Logarithmic Error |
| Min | âœ… | âœ… | Minimum Error |
| Hinge | âŒ | âŒ | Hinge Error |
| SoftCrossEntropy | âœ… | âœ… | Soft-Categorical Cross-Entropy Error |


# Metric functions

| Functionality | CPU | GPU | Comments |
| ------------- |------| -----|---------|
| CategoricalAccuracy | âœ… | âœ… | |
| TopKAccuracy | âŒ | âŒ | |
| CosineProximity | âŒ | âŒ | |
| MSE | âœ… | âœ… | Mean Squared Error |
| MAE | âœ… | âœ… | Mean Absolute Error  |
| MRE | âœ… | âœ… | Mean Relative Error |
| Sum | âœ… | âœ… | Sum Error |


# Optimizers

| Functionality | CPU | GPU | Comments |
| ------------- |------| -----|---------|
| Adadelta |âŒ | âŒ | Adadelta optimizer. |
| Adagrad | âŒ | âŒ | Adagrad optimizer. |
| Adam | âœ… | âœ… | Adam optimizer. |
| Adamax | âŒ | âŒ | Adamax optimizer from Adam paper's Section 7.  |
| Nadam | âŒ | âŒ | Nesterov Adam optimizer. |
| RMSProp |âœ… | âœ… | RMSProp optimizer.  |
| SGD | âœ… | âœ… | Stochastic gradient descent optimizer. |

