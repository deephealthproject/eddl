### Development Status

| Image | Meaning |
| ----- |---------|
|  ğŸŸ¢ï¸   | Done |
|  ğŸ”´ï¸   | Todo |
|  âš«ï¸   | Not planned / Not supported |

# Layers
---

## Core layers

| Functionality | CPU | GPU | cuDNN | ONNX | Comments |
| ------------- |------| -----| ----| ------|---------|
| Dense     | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Just your regular densely-connected NN layer. |
| Dropout   | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Applies Dropout to the input. |
| Flatten   | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Flattens the input. Does not affect the batch size. (Wrapper for Reshape) |
| Input     | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Used to instantiate a EDDL tensor. |
| Reshape   | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Reshapes an output to a certain shape. |
| Squeeze   | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | âš«ï¸ | Reshapes an output to a certain shape. |
| Unsqueeze | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | âš«ï¸ | Reshapes an output to a certain shape. |
| Permute   | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸  | Permutes the dimensions of the input according to a given pattern. |
| Embedding | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ï¸ğŸŸ¢ï¸ï¸ | Turns positive integers (indexes) into dense vectors of fixed size; (also known as mapping). e.g. `[[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]`|
| Transpose | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ï¸ğŸŸ¢ï¸ï¸ | Permute the last two dimensions |


## Activations

| Functionality | CPU | GPU | cuDNN | ONNX | Comments |
| ------------- |------| -----| -----| ------|---------|
| ELU           |  ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Exponential linear unit. |
| Exponential   |  ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ (Custom Op) | Exponential (base e) activation function. |
| HardSigmoid   |  ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Hard sigmoid activation function. |
| LeakyReLu     |  ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Leaky version of a Rectified Linear Unit.  |
| Linear |         ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ (Custom Op) | Linear (i.e. identity) activation function.  |
| PReLU |          âš«ï¸ï¸ | âš«ï¸ |âš«ï¸ | âš«ï¸ï¸ | Parametric Rectified Linear Unit.   |
| ReLu |           ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Rectified Linear Unit. |
| Softmax       |  ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Softmax activation function. |
| Selu          |  ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Scaled Exponential Linear Unit (SELU). |
| Sigmoid        | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Sigmoid activation function. |
| Softplus       | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Softplus activation function. |
| Softsign       | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Softsign activation function. |
| Tanh           | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Hyperbolic tangent activation function. |
| ThresholdedReLU | ğŸŸ¢ï¸ï¸| ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Thresholded Rectified Linear Unit. |


## Convolutional layers

| Functionality | CPU | GPU | cuDNN | ONNX | Comments |
| ------------- |------| -----| -----| ------|---------|
| Conv1D            | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | 1D convolution. |
| Conv2D            | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | 2D convolution. |
| Conv3D            | ğŸ”´ | ğŸ”´ï¸ |ğŸŸ¢ï¸ï¸ | ğŸ”´ï¸ | 3D convolution. |
| Pointwise         | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | 2D pointwise convolution. |
| DepthwiseConv2D   | ğŸ”´ï¸ | ğŸ”´ï¸ |ğŸ”´ï¸ | ğŸ”´ï¸ | 2D depthsise convolution. |
| TransposedConv2D  | ğŸ”´ï¸ | ğŸ”´ï¸ |ğŸ”´ï¸ | ğŸ”´ï¸ | Transposed convolution |
| UpSampling        | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Practically the same as `Scale(mode="nearest")`. Instead of performing nearest interpolation, this works by repeating n times the elements of each axis `[2, 1] => [2, 2, 1, 1]`. |


## Data transformation/augmentation

### Data transformations

Deterministic transformations

| Functionality | CPU | GPU | cuDNN | ONNX | Comments |
| ------------- |------| -----| -----| ------|---------|
| Crop           | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | âš«ï¸ï¸ | Crops the given image at `[(top, left), (bottom, right)]` |
| CenteredCrop   | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | âš«ï¸ | Crops the given image at the center with size (width, height)  |
| ColorJitter    | âš«ï¸ | âš«ï¸ï¸ |âš«ï¸ï¸ | âš«ï¸ | Randomly change the brightness, contrast and saturation of an image. |
| CropScale      | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | âš«ï¸ | Crop the given image at `[(top, left), (bottom, right)]` and scale it to the parent size |
| Cutout         | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | âš«ï¸ | Selects a rectangle region in an image at `[(top, left), (bottom, right)]` and erases its pixels using a constant value. |
| Flip           | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | âš«ï¸ | Flip the given image at `axis=n`. |
| Grayscale      | âš«ï¸ | âš«ï¸ |âš«ï¸ | âš«ï¸ï¸ | Convert image to grayscale. |
| HorizontalFlip | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | âš«ï¸ | Horizontally flip the given image. |
| Pad            | âš«ï¸ | âš«ï¸ |âš«ï¸ | âš«ï¸ | Pad the given image on all sides with the given "pad" value. |
| Rotate         | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | âš«ï¸ | Rotate the image by angle. |
| Scale          | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | âš«ï¸ | Resize the input image to the given size. `[height, width]` |
| Shift          | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | âš«ï¸ | Shift the input image `[a, b]` |
| VerticallyFlip | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | âš«ï¸ | Vertically flip the given image. |
| Normalize      | âš« | âš«ï¸ |âš«ï¸ | âš«ï¸ | Normalize an image with mean and standard deviation. |


### Data augmentations
Apply data transformations with random parametrization.

| Functionality | CPU | GPU | cuDNN | ONNX | Comments |
| ------------- |------| -----| -----| ------|---------|
| RandomAffine         | âš«ï¸ | âš«ï¸ | âš«ï¸ | âš«ï¸ | Random affine transformation of the image keeping center invariant: rotate+translate+scale+shear |
| RandomCrop           | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | âš«ï¸ | Crop the given image at a random location with size `[height, width]`  |
| RandomCropScale      | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | âš«ï¸ | Crop the given image randomly by the size in a range `[a, b]` by and scale it to the parent size |
| RandomCutout         | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | âš«ï¸ | Randomly selects a rectangle region in an image and erases its pixels. The random region is defined by the range `[(min_x, max_x), (min_y, max_y)]`, where these are relative values |

| RandomFlip           | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | âš«ï¸ | Flip the given image at `axis=n` randomly with a given probability. |
| RandomGrayscale      | âš« | âš« | âš« | âš«ï¸ | Randomly convert image to grayscale with a probability of p (default 0.1). |
| RandomHorizontalFlip | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | âš«ï¸ | Horizontally flip the given image randomly with a given probability. |
| RandomRotation       | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | âš«ï¸ | Rotate the image randomly by an angle defined in a range `[a, b]`. |
| RandomScale          | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | âš«ï¸ | Resize the input image randomly by the size in a range `[a, b]` |
| RandomShift          | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | âš«ï¸ | Shift the input image randomly in range `[a, b]` |
| RandomVerticalFlip   | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | âš«ï¸ | Vertically flip the given image randomly with a given probability. |


## Merge layers

| Functionality | CPU | GPU | cuDNN | ONNX | Comments |
| ------------- |------| -----| -----| ------|---------|
| Add           | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸  | Layer that adds a list of inputs. |
| Average       | ğŸ”´ï¸ | ğŸ”´ï¸ |ğŸ”´ï¸ | ğŸ”´ï¸ | Layer that averages a list of inputs. |
| Concatenate   | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Layer that concatenates a list of inputs. |
| Dot           | ğŸ”´ï¸ | ğŸ”´ï¸ |ğŸ”´ï¸ | ğŸ”´ï¸ | Layer that computes a dot product between samples in two tensors.  |
| Multiply      | ğŸ”´ï¸ | ğŸ”´ï¸ |ğŸ”´ï¸ | ğŸ”´ï¸ | Layer that multiplies (element-wise) a list of inputs. |
| Maximum       | ğŸ”´ï¸ | ğŸ”´ï¸ |ğŸ”´ï¸ | ğŸ”´ï¸ | Layer that computes the maximum (element-wise) a list of inputs. |
| Minimum       | ğŸ”´ï¸ | ğŸ”´ï¸ |ğŸ”´ï¸ | ğŸ”´ï¸ | Layer that computes the minimum (element-wise) a list of inputs. |
| Substract     | ğŸ”´ï¸ | ğŸ”´ï¸ |ğŸ”´ï¸ | ğŸ”´ï¸ | Layer that subtracts two inputs. |


## Normalization

| Functionality | CPU | GPU | cuDNN | ONNX | Comments |
| ------------- |------| -----| -----| ------|---------|
| BatchNormalization | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Batch normalization layer (Ioffe and Szegedy, 2014).  |
| LayerNormalization | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | âš« (Not in ONNX) | Layer normalization layer (Ba et al., 2016)  |
| GroupNormalization | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | âš« (Not in ONNX) | Group normalization layer (Yuxin Wu and Kaiming He, 2018).  |
| Norm               | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | âš« (Not in ONNX) |   |
| NormMax            | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | âš« (Not in ONNX) |   |
| NormMinMax         | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | âš« (Not in ONNX) |   |


## Noise layers

| Functionality | CPU | GPU | cuDNN | ONNX | Comments |
| ------------- |------| -----| -----| ------|---------|
| GaussianNoise | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ |âš« (Not in ONNX) | Apply additive zero-centered Gaussian noise. |
| UniformNoise  | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | âš« (Not in ONNX) | Apply additive zero-centered uniform noise.


## Pooling layers

| Functionality | CPU | GPU | cuDNN | ONNX | Comments |
| ------------- |------| -----| -----| ------|---------|
| MaxPool1D           | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | 1D MaxPooling operation |
| MaxPool2D           | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | 2D MaxPooling operation |
| MaxPool3D           | ğŸ”´ï¸ | ğŸ”´ï¸ | ğŸŸ¢ï¸ï¸ | ğŸ”´ï¸ï¸ | 3D MaxPooling operation |
| AveragePool1D       | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | 1D AveragePooling operation |
| AveragePool2D       | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | 2D AveragePooling operation |
| AveragePool3D       | ğŸ”´ï¸ | ğŸ”´ï¸ | ğŸŸ¢ï¸ï¸ | ğŸ”´ï¸ï¸ | 3D AveragePooling operation |
| GlobalMaxPool1D     | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | 1D GlobalMaxPooling operation |
| GlobalMaxPool2D     | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | 2D GlobalMaxPooling operation |
| GlobalMaxPool3D     | ğŸ”´ï¸ | ğŸ”´ï¸ | ğŸ”´ï¸ | ğŸ”´ï¸ï¸ | 3D GlobalMaxPooling operation |
| GlobalAveragePool1D | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | 1D GlobalAveragePooling operation |
| GlobalAveragePool2D | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | 2D GlobalAveragePooling operation |
| GlobalAveragePool3D | ğŸ”´ï¸ | ğŸ”´ï¸ | ğŸ”´ï¸ | ğŸ”´ï¸ï¸ | 3D GlobalAveragePooling operation |


## Operators layers

| Functionality | CPU | GPU | cuDNN | ONNX | Comments |
| ------------- |------| -----| -----| ------|---------|
| Abs           |  ğŸŸ¢ï¸ï¸| ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | |
| Sum           | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸ”´ï¸ | |
| Div           | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | |
| Exp           | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | |
| Log           | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | |
| Log2          |  ğŸŸ¢ï¸ï¸| ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | âš« (Not in ONNX) | |
| Log10         | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | âš« (Not in ONNX) | |
| Mult          | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | |
| Pow           | ğŸ”´ï¸ | ğŸ”´ï¸ |ğŸ”´ï¸ | ğŸ”´ï¸ | |
| Select        |  ğŸŸ¢ï¸ï¸| ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | âš« (Not in ONNX) | |
| Sqrt          |  ğŸŸ¢ï¸ï¸| ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | |
| Sub           | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | |


## Reduction layers

| Functionality | CPU | GPU | cuDNN | ONNX | Comments |
| ------------- |------| -----| -----| ------|---------|
| Max    | ğŸŸ¢ï¸ï¸| ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | |
| Mean   | ğŸŸ¢ï¸ï¸| ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | |
| Min    | ğŸŸ¢ï¸ï¸| ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | |
| Sum    | ğŸŸ¢ï¸ï¸| ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | |
| Var    | ğŸŸ¢ï¸ï¸| ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | âš« (Not in ONNX) | |
| Argmax | ğŸŸ¢ï¸ï¸| ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | |


## Recurrent layers

| Functionality | CPU | GPU | cuDNN | ONNX | Comments |
| ------------- |------| -----| -----| ------|---------|
| GRU  | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸ”´ï¸ | Gated Recurrent Unit - Cho et al. 2014. |
| LSTM | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Long Short-Term Memory layer - Hochreiter 1997. |
| RNN  | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸ”´ï¸ | Fully-connected RNN where the output is to be fed back to input. |


## Regularizer layers

| Functionality | CPU | GPU | cuDNN | ONNX | Comments |
| ------------- |------| -----| -----| ------|---------|
| L1   | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸ”´ï¸ | Lasso Regression |
| L2   | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸ”´ï¸ | Ridge Regression |
| L1L2 | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸ”´ï¸ |  |


# Initializers

| Functionality | CPU | GPU | cuDNN | Comments |
| ------------- |------| -----| ------| ---------|
| Constant        | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Initializer that generates tensors initialized to a constant value |
| GlorotNormal    | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Glorot normal initializer, also called Xavier normal initializer. |
| GlorotUniform   | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Glorot uniform initializer, also called Xavier uniform initializer. |
| HeNormal        | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | _He_ normal initializer. |
| HeUniform       | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸  |ğŸŸ¢ï¸ï¸  | _He_ uniform initializer. |
| Identity        | âš«ï¸ | âš«ï¸ | âš«ï¸ | Initializer that generates the identity matrix. |
| LeCunUniform    | âš« | âš« | âš« | LeCun uniform initializer. |
| LeCunNormal     | âš« | âš« | âš« | LeCun normal initializer. |
| Orthogonal      |  âš«ï¸| âš« | âš« | Initializer that generates a random orthogonal matrix.  |
| RandomNormal    | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Initializer that generates tensors with a normal distribution. |
| RandomUniform   | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Initializer that generates tensors with a uniform distribution.  |
| TruncatedNormal | âš« | âš«  |âš«  | Initializer that generates a truncated normal distribution.  |
| VarianceScaling | âš« | âš«ï¸ | âš«ï¸ | Initializer capable of adapting its scale to the shape of weights.  |


# Constraints

| Functionality | CPU | GPU | cuDNN | Comments |
| ------------- |------| -----| ------| ---------|
| MaxNorm    | âš«ï¸  | âš«ï¸ï¸ |âš«ï¸ï¸ | MaxNorm weight constraint. |
| MinMaxNorm | âš«ï¸  | âš«ï¸ï¸ |âš«ï¸ï¸ | MinMaxNorm weight constraint. |
| NonNeg     | âš«ï¸  | âš«ï¸ï¸ |âš«ï¸ï¸ | Constrains the weights to be non-negative.  |
| UnitNorm   | âš«ï¸  | âš«ï¸ï¸ |âš«ï¸ï¸ | Constrains the weights incident to each hidden unit to have unit norm. |


# Loss functions

| Functionality | CPU | GPU | cuDNN | Comments |
| ------------- |------| -----| ------| ---------|
| CategoricalCrossEntropy | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |  |
| BinaryCrossEntropy      | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |  |
| MSE                     | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Mean Squared Error |
| MAE                     | ğŸ”´ï¸ | ğŸ”´ï¸ | ğŸ”´ï¸ | Mean Absolute Error  |
| MRE                     | ğŸ”´ï¸ | ğŸ”´ï¸ | ğŸ”´ï¸ | Mean Relative Error |
| MSLE                    | ğŸ”´ï¸ | ğŸ”´ï¸ | ğŸ”´ï¸ | Mean Squared Logarithmic Error |
| Min                     | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Minimum Error |
| Hinge                   | âš« | âš« | âš« | Hinge Error |
| Dice                    | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸   ğŸŸ¢ï¸ï¸  | Dice loss |
| SoftCrossEntropy        | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Soft-Categorical Cross-Entropy Error |


# Metric functions

| Functionality | CPU | GPU | cuDNN | Comments |
| ------------- |------| -----| ------| ---------|
| CategoricalAccuracy | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | |
| TopKAccuracy        | âš« |âš« | âš« | |
| CosineProximity     | âš« |âš« | âš« | |
| MSE                 | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Mean Squared Error |
| MAE                 | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Mean Absolute Error  |
| MRE                 | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Mean Relative Error |
| Sum                 | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ | Sum Error |
| Dice                | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸  | Dice error |


# Optimizers

| Functionality | CPU | GPU | cuDNN | Comments |
| ------------- |------| -----| ------| ---------|
| Adadelta |ğŸ”´ | ğŸ”´ |ğŸ”´ | Adadelta optimizer. |
| Adagrad  |ğŸ”´ | ğŸ”´ |ğŸ”´ | Adagrad optimizer. |
| Adam     |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | Adam optimizer. |
| Adamax   |ğŸ”´ | ğŸ”´ |ğŸ”´ | Adamax optimizer from Adam paper's Section 7.  |
| Nadam    |ğŸ”´ | ğŸ”´ |ğŸ”´ | Nesterov Adam optimizer. |
| RMSProp  |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | RMSProp optimizer.  |
| SGD      |ğŸŸ¢ï¸ï¸ | ğŸŸ¢ï¸ï¸ |ğŸŸ¢ï¸ï¸ | Stochastic gradient descent optimizer. |

