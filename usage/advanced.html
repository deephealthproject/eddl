

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Advanced models &mdash; EDDL  documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sphinx_tabs/semantic-ui-2.4.1/segment.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sphinx_tabs/semantic-ui-2.4.1/menu.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sphinx_tabs/semantic-ui-2.4.1/tab.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sphinx_tabs/tabs.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Development" href="../videotutorials/developers.html" />
    <link rel="prev" title="Intermediate models" href="intermediate.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #185070" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/logo-eddl-small-white.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intro/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/build-options.html">Build and configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/troubleshoot.html">Troubleshoot</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/faq.html">FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">Get started</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="intermediate.html">Intermediate models</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Advanced models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#training-a-vgg16">Training a VGG16</a></li>
<li class="toctree-l2"><a class="reference internal" href="#training-a-resnet50">Training a ResNet50</a></li>
<li class="toctree-l2"><a class="reference internal" href="#training-a-u-net">Training a U-Net</a></li>
<li class="toctree-l2"><a class="reference internal" href="#training-a-rnn">Training a RNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="#training-a-lstm">Training a LSTM</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Videotutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../videotutorials/developers.html">Development</a></li>
<li class="toctree-l1"><a class="reference internal" href="../videotutorials/usage.html">Showcase</a></li>
</ul>
<p class="caption"><span class="caption-text">Layers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../layers/core.html">Core</a></li>
<li class="toctree-l1"><a class="reference internal" href="../layers/activations.html">Activations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../layers/data_augmentation.html">Data augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../layers/data_transformation.html">Data transformation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../layers/convolutional.html">Convolutions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../layers/noise.html">Noise Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../layers/pooling.html">Pooling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../layers/normalization.html">Normalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../layers/merge.html">Merge</a></li>
<li class="toctree-l1"><a class="reference internal" href="../layers/generators.html">Generators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../layers/operators.html">Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../layers/reduction.html">Reduction Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../layers/rnn.html">Recurrent</a></li>
</ul>
<p class="caption"><span class="caption-text">Model</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../model/model.html">Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model/onnx.html">ONNX</a></li>
</ul>
<p class="caption"><span class="caption-text">Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../training/coarse.html">Coarse training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training/fine_grained.html">Fine-grained training</a></li>
</ul>
<p class="caption"><span class="caption-text">Test &amp; Score</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../test_score/test_score.html">Test &amp; Score</a></li>
</ul>
<p class="caption"><span class="caption-text">Bundle</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../bundle/losses.html">Losses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bundle/metrics.html">Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bundle/regularizers.html">Regularizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bundle/initializers.html">Initializers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bundle/optimizers.html">Optimizers</a></li>
</ul>
<p class="caption"><span class="caption-text">Computing Services</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../bundle/computing_service.html">CPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bundle/computing_service.html#gpu">GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bundle/computing_service.html#fpga">FPGA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bundle/computing_service.html#compss">COMPSS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bundle/computing_service.html#serialization">Serialization</a></li>
</ul>
<p class="caption"><span class="caption-text">Datasets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../datasets/classification.html">Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/segmentation.html">Segmentation</a></li>
</ul>
<p class="caption"><span class="caption-text">Tensor</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tensor/create.html">Creation Routines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor/manipulation.html">Manipulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor/image.html">Image operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor/indexing.html">Indexing &amp; Sorting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor/input_output.html">Input/Output Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor/linear_algebra.html">Linear algebra</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor/logic_functions.html">Logic functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor/math.html">Mathematical functions</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">EDDL</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Advanced models</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/usage/advanced.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="advanced-models">
<h1>Advanced models<a class="headerlink" href="#advanced-models" title="Permalink to this headline">¶</a></h1>
<p>This short guide explains how to train advanced models.</p>
<div class="section" id="training-a-vgg16">
<h2>Training a VGG16<a class="headerlink" href="#training-a-vgg16" title="Permalink to this headline">¶</a></h2>
<p>This example trains and evaluates VGG16 with Group Normalization using CIFAR-10. <a class="reference external" href="https://github.com/deephealthproject/eddl/blob/master/examples/nn/2_cifar10/4_cifar_vgg16_bn.cpp">[source]</a></p>
<img alt="../_images/vgg16.png" src="../_images/vgg16.png" />
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span> <span class="cpf">&lt;cstdio&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;cstdlib&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp"></span>

<span class="cp">#include</span> <span class="cpf">&quot;eddl/apis/eddl.h&quot;</span><span class="cp"></span>


<span class="k">using</span> <span class="k">namespace</span> <span class="n">eddl</span><span class="p">;</span>

<span class="c1">//////////////////////////////////</span>
<span class="c1">// cifar_vgg16_bn.cpp:</span>
<span class="c1">// vgg16 with GroupNorm</span>
<span class="c1">// Using fit for training</span>
<span class="c1">//////////////////////////////////</span>

<span class="n">layer</span> <span class="nf">Block1</span><span class="p">(</span><span class="n">layer</span> <span class="n">l</span><span class="p">,</span><span class="kt">int</span> <span class="n">filters</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">ReLu</span><span class="p">(</span><span class="n">GroupNormalization</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="n">filters</span><span class="p">,{</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">},{</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">}),</span><span class="mi">4</span><span class="p">));</span>
<span class="p">}</span>
<span class="n">layer</span> <span class="nf">Block3_2</span><span class="p">(</span><span class="n">layer</span> <span class="n">l</span><span class="p">,</span><span class="kt">int</span> <span class="n">filters</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">l</span><span class="o">=</span><span class="n">ReLu</span><span class="p">(</span><span class="n">GroupNormalization</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="n">filters</span><span class="p">,{</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">},{</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">}),</span><span class="mi">4</span><span class="p">));</span>
  <span class="n">l</span><span class="o">=</span><span class="n">ReLu</span><span class="p">(</span><span class="n">GroupNormalization</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="n">filters</span><span class="p">,{</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">},{</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">}),</span><span class="mi">4</span><span class="p">));</span>
  <span class="k">return</span> <span class="n">l</span><span class="p">;</span>
<span class="p">}</span>


<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">){</span>

  <span class="c1">// download CIFAR data</span>
  <span class="n">download_cifar10</span><span class="p">();</span>

  <span class="c1">// Settings</span>
  <span class="kt">int</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">8</span><span class="p">;</span> <span class="c1">// very small batch to test GroupNormalization</span>
  <span class="kt">int</span> <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>

  <span class="c1">// network</span>
  <span class="n">layer</span> <span class="n">in</span><span class="o">=</span><span class="n">Input</span><span class="p">({</span><span class="mi">3</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">});</span>
  <span class="n">layer</span> <span class="n">l</span><span class="o">=</span><span class="n">in</span><span class="p">;</span>

  <span class="c1">// Data augmentation</span>
  <span class="n">l</span> <span class="o">=</span> <span class="n">RandomCropScale</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="p">{</span><span class="mf">0.8f</span><span class="p">,</span> <span class="mf">1.0f</span><span class="p">});</span>
  <span class="n">l</span> <span class="o">=</span> <span class="n">RandomFlip</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span>

  <span class="n">l</span><span class="o">=</span><span class="n">MaxPool</span><span class="p">(</span><span class="n">Block3_2</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="mi">64</span><span class="p">));</span>
  <span class="n">l</span><span class="o">=</span><span class="n">MaxPool</span><span class="p">(</span><span class="n">Block3_2</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="mi">128</span><span class="p">));</span>
  <span class="n">l</span><span class="o">=</span><span class="n">MaxPool</span><span class="p">(</span><span class="n">Block1</span><span class="p">(</span><span class="n">Block3_2</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="mi">256</span><span class="p">),</span><span class="mi">256</span><span class="p">));</span>
  <span class="n">l</span><span class="o">=</span><span class="n">MaxPool</span><span class="p">(</span><span class="n">Block1</span><span class="p">(</span><span class="n">Block3_2</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="mi">512</span><span class="p">),</span><span class="mi">512</span><span class="p">));</span>
  <span class="n">l</span><span class="o">=</span><span class="n">MaxPool</span><span class="p">(</span><span class="n">Block1</span><span class="p">(</span><span class="n">Block3_2</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="mi">512</span><span class="p">),</span><span class="mi">512</span><span class="p">));</span>

  <span class="n">l</span><span class="o">=</span><span class="n">Reshape</span><span class="p">(</span><span class="n">l</span><span class="p">,{</span><span class="mi">-1</span><span class="p">});</span>
  <span class="n">l</span><span class="o">=</span><span class="n">ReLu</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="mi">512</span><span class="p">)));</span>

  <span class="n">layer</span> <span class="n">out</span><span class="o">=</span> <span class="n">Softmax</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">));</span>

  <span class="c1">// net define input and output layers list</span>
  <span class="n">model</span> <span class="n">net</span><span class="o">=</span><span class="n">Model</span><span class="p">({</span><span class="n">in</span><span class="p">},{</span><span class="n">out</span><span class="p">});</span>


  <span class="c1">// Build model</span>
  <span class="n">build</span><span class="p">(</span><span class="n">net</span><span class="p">,</span>
    <span class="n">adam</span><span class="p">(</span><span class="mf">0.001</span><span class="p">),</span> <span class="c1">// Optimizer</span>
    <span class="p">{</span><span class="s">&quot;softmax_cross_entropy&quot;</span><span class="p">},</span> <span class="c1">// Losses</span>
    <span class="p">{</span><span class="s">&quot;categorical_accuracy&quot;</span><span class="p">},</span> <span class="c1">// Metrics</span>
    <span class="n">CS_GPU</span><span class="p">({</span><span class="mi">1</span><span class="p">})</span> <span class="c1">// one GPU</span>
    <span class="c1">//CS_GPU({1,1},100) // two GPU with weight sync every 100 batches</span>
    <span class="c1">//CS_CPU()</span>
  <span class="p">);</span>

  <span class="c1">// plot the model</span>
  <span class="n">plot</span><span class="p">(</span><span class="n">net</span><span class="p">,</span><span class="s">&quot;model.pdf&quot;</span><span class="p">,</span><span class="s">&quot;TB&quot;</span><span class="p">);</span>  <span class="c1">//Top Bottom plot</span>

  <span class="c1">// get some info from the network</span>
  <span class="n">summary</span><span class="p">(</span><span class="n">net</span><span class="p">);</span>

  <span class="c1">// Load and preprocess training data</span>
  <span class="n">Tensor</span><span class="o">*</span> <span class="n">x_train</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;cifar_trX.bin&quot;</span><span class="p">);</span>
  <span class="n">Tensor</span><span class="o">*</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;cifar_trY.bin&quot;</span><span class="p">);</span>
  <span class="n">x_train</span><span class="o">-&gt;</span><span class="n">div_</span><span class="p">(</span><span class="mf">255.0f</span><span class="p">);</span>

  <span class="c1">// Load and preprocess test data</span>
  <span class="n">Tensor</span><span class="o">*</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;cifar_tsX.bin&quot;</span><span class="p">);</span>
  <span class="n">Tensor</span><span class="o">*</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;cifar_tsY.bin&quot;</span><span class="p">);</span>
  <span class="n">x_test</span><span class="o">-&gt;</span><span class="n">div_</span><span class="p">(</span><span class="mf">255.0f</span><span class="p">);</span>


  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="n">epochs</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// training, list of input and output tensors, batch, epochs</span>
    <span class="n">fit</span><span class="p">(</span><span class="n">net</span><span class="p">,{</span><span class="n">x_train</span><span class="p">},{</span><span class="n">y_train</span><span class="p">},</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
    <span class="c1">// Evaluate test</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;Evaluate test:&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
    <span class="n">evaluate</span><span class="p">(</span><span class="n">net</span><span class="p">,{</span><span class="n">x_test</span><span class="p">},{</span><span class="n">y_test</span><span class="p">});</span>
  <span class="p">}</span>


<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="training-a-resnet50">
<h2>Training a ResNet50<a class="headerlink" href="#training-a-resnet50" title="Permalink to this headline">¶</a></h2>
<p>This example trains and evaluates ResNet50 using CIFAR-10. <a class="reference external" href="https://github.com/deephealthproject/eddl/blob/master/examples/nn/2_cifar10/7_cifar_resnet50_da_bn.cpp">[source]</a></p>
<a class="reference internal image-reference" href="../_images/resnet50.svg"><img alt="../_images/resnet50.svg" height="1568" src="../_images/resnet50.svg" width="71184" /></a>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span> <span class="cpf">&lt;cstdio&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;cstdlib&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp"></span>

<span class="cp">#include</span> <span class="cpf">&quot;eddl/apis/eddl.h&quot;</span><span class="cp"></span>


<span class="k">using</span> <span class="k">namespace</span> <span class="n">eddl</span><span class="p">;</span>

<span class="c1">//////////////////////////////////</span>
<span class="c1">// cifar_resnet50_da_bn.cpp:</span>
<span class="c1">// Resnet50 with</span>
<span class="c1">// BatchNorm</span>
<span class="c1">// Data Augmentation</span>
<span class="c1">// Using fit for training</span>
<span class="c1">//////////////////////////////////</span>

<span class="n">layer</span> <span class="nf">BN</span><span class="p">(</span><span class="n">layer</span> <span class="n">l</span><span class="p">)</span>
<span class="p">{</span>
  <span class="k">return</span> <span class="n">BatchNormalization</span><span class="p">(</span><span class="n">l</span><span class="p">);</span>
  <span class="c1">//return l;</span>
<span class="p">}</span>

<span class="n">layer</span> <span class="nf">BG</span><span class="p">(</span><span class="n">layer</span> <span class="n">l</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">//return GaussianNoise(BN(l),0.3);</span>
  <span class="k">return</span> <span class="n">BN</span><span class="p">(</span><span class="n">l</span><span class="p">);</span>
<span class="p">}</span>


<span class="n">layer</span> <span class="nf">ResBlock</span><span class="p">(</span><span class="n">layer</span> <span class="n">l</span><span class="p">,</span> <span class="kt">int</span> <span class="n">filters</span><span class="p">,</span><span class="kt">int</span> <span class="n">half</span><span class="p">,</span> <span class="kt">int</span> <span class="n">expand</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">layer</span> <span class="n">in</span><span class="o">=</span><span class="n">l</span><span class="p">;</span>

  <span class="n">l</span><span class="o">=</span><span class="n">ReLu</span><span class="p">(</span><span class="n">BG</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="n">filters</span><span class="p">,{</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">},{</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">},</span><span class="s">&quot;same&quot;</span><span class="p">,</span><span class="nb">false</span><span class="p">)));</span>

  <span class="k">if</span> <span class="p">(</span><span class="n">half</span><span class="p">)</span>
    <span class="n">l</span><span class="o">=</span><span class="n">ReLu</span><span class="p">(</span><span class="n">BG</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="n">filters</span><span class="p">,{</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">},{</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span><span class="s">&quot;same&quot;</span><span class="p">,</span><span class="nb">false</span><span class="p">)));</span>
  <span class="k">else</span>
    <span class="n">l</span><span class="o">=</span><span class="n">ReLu</span><span class="p">(</span><span class="n">BG</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="n">filters</span><span class="p">,{</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">},{</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">},</span><span class="s">&quot;same&quot;</span><span class="p">,</span><span class="nb">false</span><span class="p">)));</span>

  <span class="n">l</span><span class="o">=</span><span class="n">BG</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="mi">4</span><span class="o">*</span><span class="n">filters</span><span class="p">,{</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">},{</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">},</span><span class="s">&quot;same&quot;</span><span class="p">,</span><span class="nb">false</span><span class="p">));</span>

  <span class="k">if</span> <span class="p">(</span><span class="n">half</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ReLu</span><span class="p">(</span><span class="n">Sum</span><span class="p">(</span><span class="n">BG</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">in</span><span class="p">,</span><span class="mi">4</span><span class="o">*</span><span class="n">filters</span><span class="p">,{</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">},{</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span><span class="s">&quot;same&quot;</span><span class="p">,</span><span class="nb">false</span><span class="p">)),</span><span class="n">l</span><span class="p">));</span>
  <span class="k">else</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">expand</span><span class="p">)</span> <span class="k">return</span> <span class="n">ReLu</span><span class="p">(</span><span class="n">Sum</span><span class="p">(</span><span class="n">BG</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">in</span><span class="p">,</span><span class="mi">4</span><span class="o">*</span><span class="n">filters</span><span class="p">,{</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">},{</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">},</span><span class="s">&quot;same&quot;</span><span class="p">,</span><span class="nb">false</span><span class="p">)),</span><span class="n">l</span><span class="p">));</span>
    <span class="k">else</span> <span class="k">return</span> <span class="n">ReLu</span><span class="p">(</span><span class="n">Sum</span><span class="p">(</span><span class="n">in</span><span class="p">,</span><span class="n">l</span><span class="p">));</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">){</span>

  <span class="c1">// download CIFAR data</span>
  <span class="n">download_cifar10</span><span class="p">();</span>

  <span class="c1">// Settings</span>
  <span class="kt">int</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">batch_size</span> <span class="o">=</span><span class="mi">16</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>

  <span class="c1">// network</span>
  <span class="n">layer</span> <span class="n">in</span><span class="o">=</span><span class="n">Input</span><span class="p">({</span><span class="mi">3</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">});</span>
  <span class="n">layer</span> <span class="n">l</span><span class="o">=</span><span class="n">in</span><span class="p">;</span>

  <span class="c1">// Data augmentation</span>

  <span class="n">l</span> <span class="o">=</span> <span class="n">RandomCropScale</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="p">{</span><span class="mf">0.8f</span><span class="p">,</span> <span class="mf">1.0f</span><span class="p">});</span>
  <span class="n">l</span> <span class="o">=</span> <span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="n">l</span><span class="p">);</span>

  <span class="c1">// Resnet-50</span>

  <span class="n">l</span><span class="o">=</span><span class="n">ReLu</span><span class="p">(</span><span class="n">BG</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="mi">64</span><span class="p">,{</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">},{</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">},</span><span class="s">&quot;same&quot;</span><span class="p">,</span><span class="nb">false</span><span class="p">)));</span> <span class="c1">//{1,1}</span>
  <span class="c1">//l=MaxPool(l,{3,3},{1,1},&quot;same&quot;);</span>

  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="mi">3</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
    <span class="n">l</span><span class="o">=</span><span class="n">ResBlock</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="o">==</span><span class="mi">0</span><span class="p">);</span> <span class="c1">// not half but expand the first</span>

  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="mi">4</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
    <span class="n">l</span><span class="o">=</span><span class="n">ResBlock</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span><span class="n">i</span><span class="o">==</span><span class="mi">0</span><span class="p">);</span>

  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="mi">6</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
    <span class="n">l</span><span class="o">=</span><span class="n">ResBlock</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span><span class="n">i</span><span class="o">==</span><span class="mi">0</span><span class="p">);</span>

  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="mi">3</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
    <span class="n">l</span><span class="o">=</span><span class="n">ResBlock</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="mi">512</span><span class="p">,</span><span class="n">i</span><span class="o">==</span><span class="mi">0</span><span class="p">);</span>

  <span class="n">l</span><span class="o">=</span><span class="n">MaxPool</span><span class="p">(</span><span class="n">l</span><span class="p">,{</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">});</span>  <span class="c1">// should be avgpool</span>

  <span class="n">l</span><span class="o">=</span><span class="n">Reshape</span><span class="p">(</span><span class="n">l</span><span class="p">,{</span><span class="mi">-1</span><span class="p">});</span>

  <span class="n">layer</span> <span class="n">out</span><span class="o">=</span><span class="n">Activation</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="n">num_classes</span><span class="p">),</span><span class="s">&quot;softmax&quot;</span><span class="p">);</span>

  <span class="c1">// net define input and output layers list</span>
  <span class="n">model</span> <span class="n">net</span><span class="o">=</span><span class="n">Model</span><span class="p">({</span><span class="n">in</span><span class="p">},{</span><span class="n">out</span><span class="p">});</span>


  <span class="c1">// Build model</span>
  <span class="n">build</span><span class="p">(</span><span class="n">net</span><span class="p">,</span>
  <span class="n">sgd</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span><span class="mf">0.9</span><span class="p">),</span> <span class="c1">// Optimizer</span>
    <span class="p">{</span><span class="s">&quot;soft_cross_entropy&quot;</span><span class="p">},</span> <span class="c1">// Losses</span>
    <span class="p">{</span><span class="s">&quot;categorical_accuracy&quot;</span><span class="p">},</span> <span class="c1">// Metrics</span>
    <span class="n">CS_GPU</span><span class="p">({</span><span class="mi">1</span><span class="p">})</span> <span class="c1">// one GPU</span>
    <span class="c1">//CS_GPU({1,1},100) // two GPU with weight sync every 100 batches</span>
    <span class="c1">//CS_CPU()</span>
  <span class="p">);</span>

  <span class="c1">// plot the model</span>
  <span class="n">plot</span><span class="p">(</span><span class="n">net</span><span class="p">,</span><span class="s">&quot;model.pdf&quot;</span><span class="p">,</span><span class="s">&quot;TB&quot;</span><span class="p">);</span>  <span class="c1">// TB --&gt; Top-Bottom mode for dot (graphviz)</span>

  <span class="c1">// get some info from the network</span>
  <span class="n">summary</span><span class="p">(</span><span class="n">net</span><span class="p">);</span>



  <span class="c1">// Load and preprocess training data</span>
  <span class="n">Tensor</span><span class="o">*</span> <span class="n">x_train</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;cifar_trX.bin&quot;</span><span class="p">);</span>
  <span class="n">Tensor</span><span class="o">*</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;cifar_trY.bin&quot;</span><span class="p">);</span>
  <span class="n">x_train</span><span class="o">-&gt;</span><span class="n">div_</span><span class="p">(</span><span class="mf">255.0f</span><span class="p">);</span>

  <span class="c1">// Load and preprocess test data</span>
  <span class="n">Tensor</span><span class="o">*</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;cifar_tsX.bin&quot;</span><span class="p">);</span>
  <span class="n">Tensor</span><span class="o">*</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;cifar_tsY.bin&quot;</span><span class="p">);</span>
  <span class="n">x_test</span><span class="o">-&gt;</span><span class="n">div_</span><span class="p">(</span><span class="mf">255.0f</span><span class="p">);</span>


  <span class="kt">float</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">;</span>
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">j</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">j</span><span class="o">&lt;</span><span class="mi">3</span><span class="p">;</span><span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">lr</span><span class="o">/=</span><span class="mf">10.0</span><span class="p">;</span>

    <span class="n">setlr</span><span class="p">(</span><span class="n">net</span><span class="p">,{</span><span class="n">lr</span><span class="p">,</span><span class="mf">0.9</span><span class="p">});</span>

    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="n">epochs</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="c1">// training, list of input and output tensors, batch, epochs</span>
      <span class="n">fit</span><span class="p">(</span><span class="n">net</span><span class="p">,{</span><span class="n">x_train</span><span class="p">},{</span><span class="n">y_train</span><span class="p">},</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>

      <span class="c1">// Evaluate test</span>
      <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;Evaluate test:&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
      <span class="n">evaluate</span><span class="p">(</span><span class="n">net</span><span class="p">,{</span><span class="n">x_test</span><span class="p">},{</span><span class="n">y_test</span><span class="p">});</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="training-a-u-net">
<h2>Training a U-Net<a class="headerlink" href="#training-a-u-net" title="Permalink to this headline">¶</a></h2>
<p>This example trains and evaluates a U-Net. <a class="reference external" href="https://github.com/deephealthproject/eddl/blob/master/examples/nn/3_drive/1_drive_seg.cpp">[source]</a></p>
<a class="reference internal image-reference" href="../_images/segnet.svg"><img alt="../_images/segnet.svg" height="3168" src="../_images/segnet.svg" width="86720" /></a>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span> <span class="cpf">&lt;cstdio&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;cstdlib&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp"></span>

<span class="cp">#include</span> <span class="cpf">&quot;eddl/apis/eddl.h&quot;</span><span class="cp"></span>


<span class="k">using</span> <span class="k">namespace</span> <span class="n">eddl</span><span class="p">;</span>

<span class="cp">#define USE_CONCAT 1</span>

<span class="c1">//////////////////////////////////</span>
<span class="c1">// Drive segmentation</span>
<span class="c1">// https://drive.grand-challenge.org/DRIVE/</span>
<span class="c1">// A Multi-GPU segmentation example</span>
<span class="c1">// Data Augmentation graph</span>
<span class="c1">// Segmentation graph</span>
<span class="c1">//////////////////////////////////</span>



<span class="c1">// from use case repo:</span>
<span class="n">layer</span> <span class="nf">UNetWithPadding</span><span class="p">(</span><span class="n">layer</span> <span class="n">x</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">layer</span> <span class="n">x2</span><span class="p">;</span>
    <span class="n">layer</span> <span class="n">x3</span><span class="p">;</span>
    <span class="n">layer</span> <span class="n">x4</span><span class="p">;</span>
    <span class="n">layer</span> <span class="n">x5</span><span class="p">;</span>

    <span class="kt">int</span> <span class="n">depth</span><span class="o">=</span><span class="mi">32</span><span class="p">;</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">LeakyReLu</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="p">{</span> <span class="mi">3</span><span class="p">,</span><span class="mi">3</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">},</span> <span class="s">&quot;same&quot;</span><span class="p">));</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">LeakyReLu</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="p">{</span> <span class="mi">3</span><span class="p">,</span><span class="mi">3</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">},</span> <span class="s">&quot;same&quot;</span><span class="p">));</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">MaxPool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">{</span> <span class="mi">2</span><span class="p">,</span><span class="mi">2</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">2</span><span class="p">,</span><span class="mi">2</span> <span class="p">});</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">LeakyReLu</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">depth</span><span class="p">,</span> <span class="p">{</span> <span class="mi">3</span><span class="p">,</span><span class="mi">3</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">},</span> <span class="s">&quot;same&quot;</span><span class="p">));</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">LeakyReLu</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">depth</span><span class="p">,</span> <span class="p">{</span> <span class="mi">3</span><span class="p">,</span><span class="mi">3</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">},</span> <span class="s">&quot;same&quot;</span><span class="p">));</span>
    <span class="n">x3</span> <span class="o">=</span> <span class="n">MaxPool</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="p">{</span> <span class="mi">2</span><span class="p">,</span><span class="mi">2</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">2</span><span class="p">,</span><span class="mi">2</span> <span class="p">});</span>
    <span class="n">x3</span> <span class="o">=</span> <span class="n">LeakyReLu</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">x3</span><span class="p">,</span> <span class="mi">4</span><span class="o">*</span><span class="n">depth</span><span class="p">,</span> <span class="p">{</span> <span class="mi">3</span><span class="p">,</span><span class="mi">3</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">},</span> <span class="s">&quot;same&quot;</span><span class="p">));</span>
    <span class="n">x3</span> <span class="o">=</span> <span class="n">LeakyReLu</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">x3</span><span class="p">,</span> <span class="mi">4</span><span class="o">*</span><span class="n">depth</span><span class="p">,</span> <span class="p">{</span> <span class="mi">3</span><span class="p">,</span><span class="mi">3</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">},</span> <span class="s">&quot;same&quot;</span><span class="p">));</span>
    <span class="n">x4</span> <span class="o">=</span> <span class="n">MaxPool</span><span class="p">(</span><span class="n">x3</span><span class="p">,</span> <span class="p">{</span> <span class="mi">2</span><span class="p">,</span><span class="mi">2</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">2</span><span class="p">,</span><span class="mi">2</span> <span class="p">});</span>
    <span class="n">x4</span> <span class="o">=</span> <span class="n">LeakyReLu</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">x4</span><span class="p">,</span> <span class="mi">8</span><span class="o">*</span><span class="n">depth</span><span class="p">,</span> <span class="p">{</span> <span class="mi">3</span><span class="p">,</span><span class="mi">3</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">},</span> <span class="s">&quot;same&quot;</span><span class="p">));</span>
    <span class="n">x4</span> <span class="o">=</span> <span class="n">LeakyReLu</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">x4</span><span class="p">,</span> <span class="mi">8</span><span class="o">*</span><span class="n">depth</span><span class="p">,</span> <span class="p">{</span> <span class="mi">3</span><span class="p">,</span><span class="mi">3</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">},</span> <span class="s">&quot;same&quot;</span><span class="p">));</span>
    <span class="n">x5</span> <span class="o">=</span> <span class="n">MaxPool</span><span class="p">(</span><span class="n">x4</span><span class="p">,</span> <span class="p">{</span> <span class="mi">2</span><span class="p">,</span><span class="mi">2</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">2</span><span class="p">,</span><span class="mi">2</span> <span class="p">});</span>
    <span class="n">x5</span> <span class="o">=</span> <span class="n">LeakyReLu</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">x5</span><span class="p">,</span> <span class="mi">8</span><span class="o">*</span><span class="n">depth</span><span class="p">,</span> <span class="p">{</span> <span class="mi">3</span><span class="p">,</span><span class="mi">3</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">},</span> <span class="s">&quot;same&quot;</span><span class="p">));</span>
    <span class="n">x5</span> <span class="o">=</span> <span class="n">LeakyReLu</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">x5</span><span class="p">,</span> <span class="mi">8</span><span class="o">*</span><span class="n">depth</span><span class="p">,</span> <span class="p">{</span> <span class="mi">3</span><span class="p">,</span><span class="mi">3</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">},</span> <span class="s">&quot;same&quot;</span><span class="p">));</span>
    <span class="n">x5</span> <span class="o">=</span> <span class="n">Conv</span><span class="p">(</span><span class="n">UpSampling</span><span class="p">(</span><span class="n">x5</span><span class="p">,</span> <span class="p">{</span> <span class="mi">2</span><span class="p">,</span><span class="mi">2</span> <span class="p">}),</span> <span class="mi">8</span><span class="o">*</span><span class="n">depth</span><span class="p">,</span> <span class="p">{</span> <span class="mi">2</span><span class="p">,</span><span class="mi">2</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">},</span> <span class="s">&quot;same&quot;</span><span class="p">);</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">USE_CONCAT</span><span class="p">)</span> <span class="n">x4</span> <span class="o">=</span> <span class="n">Concat</span><span class="p">({</span><span class="n">x4</span><span class="p">,</span><span class="n">x5</span><span class="p">});</span>
    <span class="k">else</span> <span class="n">x4</span> <span class="o">=</span> <span class="n">Sum</span><span class="p">(</span><span class="n">x4</span><span class="p">,</span><span class="n">x5</span><span class="p">);</span>
    <span class="n">x4</span> <span class="o">=</span> <span class="n">LeakyReLu</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">x4</span><span class="p">,</span> <span class="mi">8</span><span class="o">*</span><span class="n">depth</span><span class="p">,</span> <span class="p">{</span> <span class="mi">3</span><span class="p">,</span><span class="mi">3</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">},</span> <span class="s">&quot;same&quot;</span><span class="p">));</span>
    <span class="n">x4</span> <span class="o">=</span> <span class="n">LeakyReLu</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">x4</span><span class="p">,</span> <span class="mi">8</span><span class="o">*</span><span class="n">depth</span><span class="p">,</span> <span class="p">{</span> <span class="mi">3</span><span class="p">,</span><span class="mi">3</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">},</span> <span class="s">&quot;same&quot;</span><span class="p">));</span>
    <span class="n">x4</span> <span class="o">=</span> <span class="n">Conv</span><span class="p">(</span><span class="n">UpSampling</span><span class="p">(</span><span class="n">x4</span><span class="p">,</span> <span class="p">{</span> <span class="mi">2</span><span class="p">,</span><span class="mi">2</span> <span class="p">}),</span> <span class="mi">4</span><span class="o">*</span><span class="n">depth</span><span class="p">,</span> <span class="p">{</span> <span class="mi">2</span><span class="p">,</span><span class="mi">2</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">},</span> <span class="s">&quot;same&quot;</span><span class="p">);</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">USE_CONCAT</span><span class="p">)</span> <span class="n">x3</span> <span class="o">=</span> <span class="n">Concat</span><span class="p">({</span><span class="n">x3</span><span class="p">,</span><span class="n">x4</span><span class="p">});</span>
    <span class="k">else</span> <span class="n">x3</span> <span class="o">=</span> <span class="n">Sum</span><span class="p">(</span><span class="n">x3</span><span class="p">,</span><span class="n">x4</span><span class="p">);</span>
    <span class="n">x3</span> <span class="o">=</span> <span class="n">LeakyReLu</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">x3</span><span class="p">,</span> <span class="mi">4</span><span class="o">*</span><span class="n">depth</span><span class="p">,</span> <span class="p">{</span> <span class="mi">3</span><span class="p">,</span><span class="mi">3</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">},</span> <span class="s">&quot;same&quot;</span><span class="p">));</span>
    <span class="n">x3</span> <span class="o">=</span> <span class="n">LeakyReLu</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">x3</span><span class="p">,</span> <span class="mi">4</span><span class="o">*</span><span class="n">depth</span><span class="p">,</span> <span class="p">{</span> <span class="mi">3</span><span class="p">,</span><span class="mi">3</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">},</span> <span class="s">&quot;same&quot;</span><span class="p">));</span>
    <span class="n">x3</span> <span class="o">=</span> <span class="n">Conv</span><span class="p">(</span><span class="n">UpSampling</span><span class="p">(</span><span class="n">x3</span><span class="p">,</span> <span class="p">{</span> <span class="mi">2</span><span class="p">,</span><span class="mi">2</span> <span class="p">}),</span> <span class="mi">2</span><span class="o">*</span><span class="n">depth</span><span class="p">,</span> <span class="p">{</span> <span class="mi">2</span><span class="p">,</span><span class="mi">2</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">},</span> <span class="s">&quot;same&quot;</span><span class="p">);</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">USE_CONCAT</span><span class="p">)</span> <span class="n">x2</span> <span class="o">=</span> <span class="n">Concat</span><span class="p">({</span><span class="n">x2</span><span class="p">,</span><span class="n">x3</span><span class="p">});</span>
    <span class="k">else</span> <span class="n">x2</span> <span class="o">=</span> <span class="n">Sum</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span><span class="n">x3</span><span class="p">);</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">LeakyReLu</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">depth</span><span class="p">,</span> <span class="p">{</span> <span class="mi">3</span><span class="p">,</span><span class="mi">3</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">},</span> <span class="s">&quot;same&quot;</span><span class="p">));</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">LeakyReLu</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">depth</span><span class="p">,</span> <span class="p">{</span> <span class="mi">3</span><span class="p">,</span><span class="mi">3</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">},</span> <span class="s">&quot;same&quot;</span><span class="p">));</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">Conv</span><span class="p">(</span><span class="n">UpSampling</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="p">{</span> <span class="mi">2</span><span class="p">,</span><span class="mi">2</span> <span class="p">}),</span> <span class="n">depth</span><span class="p">,</span> <span class="p">{</span> <span class="mi">2</span><span class="p">,</span><span class="mi">2</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">},</span> <span class="s">&quot;same&quot;</span><span class="p">);</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">USE_CONCAT</span><span class="p">)</span> <span class="n">x</span> <span class="o">=</span> <span class="n">Concat</span><span class="p">({</span><span class="n">x</span><span class="p">,</span><span class="n">x2</span><span class="p">});</span>
    <span class="k">else</span> <span class="n">x</span> <span class="o">=</span> <span class="n">Sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">x2</span><span class="p">);</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">LeakyReLu</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="p">{</span> <span class="mi">3</span><span class="p">,</span><span class="mi">3</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">},</span> <span class="s">&quot;same&quot;</span><span class="p">));</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">LeakyReLu</span><span class="p">(</span><span class="n">Conv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="p">{</span> <span class="mi">3</span><span class="p">,</span><span class="mi">3</span> <span class="p">},</span> <span class="p">{</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">},</span> <span class="s">&quot;same&quot;</span><span class="p">));</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">{</span> <span class="mi">1</span><span class="p">,</span><span class="mi">1</span> <span class="p">});</span>

    <span class="k">return</span> <span class="n">x</span><span class="p">;</span>
<span class="p">}</span>


<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">){</span>

    <span class="c1">// Download Dataset</span>
    <span class="n">download_drive</span><span class="p">();</span>

    <span class="c1">// Settings</span>
    <span class="kt">int</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">100000</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">batch_size</span> <span class="o">=</span><span class="mi">3</span><span class="p">;</span>

    <span class="c1">//////////////////////////////////////////////////////////////</span>
    <span class="c1">// Network for Data Augmentation</span>
    <span class="n">layer</span> <span class="n">in1</span><span class="o">=</span><span class="n">Input</span><span class="p">({</span><span class="mi">3</span><span class="p">,</span><span class="mi">584</span><span class="p">,</span><span class="mi">584</span><span class="p">});</span>
    <span class="n">layer</span> <span class="n">in2</span><span class="o">=</span><span class="n">Input</span><span class="p">({</span><span class="mi">1</span><span class="p">,</span><span class="mi">584</span><span class="p">,</span><span class="mi">584</span><span class="p">});</span>

    <span class="n">layer</span> <span class="n">l</span><span class="o">=</span><span class="n">Concat</span><span class="p">({</span><span class="n">in1</span><span class="p">,</span><span class="n">in2</span><span class="p">});</span>   <span class="c1">// Cat image and mask</span>
    <span class="n">l</span><span class="o">=</span> <span class="n">RandomCropScale</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="p">{</span><span class="mf">0.9f</span><span class="p">,</span> <span class="mf">1.0f</span><span class="p">});</span> <span class="c1">// Random Crop and Scale to orig size</span>
    <span class="n">l</span><span class="o">=</span> <span class="n">CenteredCrop</span><span class="p">(</span><span class="n">l</span><span class="p">,{</span><span class="mi">512</span><span class="p">,</span><span class="mi">512</span><span class="p">});</span>         <span class="c1">// Crop to work with sizes power 2</span>
    <span class="n">layer</span> <span class="n">img</span><span class="o">=</span><span class="n">Select</span><span class="p">(</span><span class="n">l</span><span class="p">,{</span><span class="s">&quot;0:3&quot;</span><span class="p">});</span> <span class="c1">// UnCat [0-2] image</span>
    <span class="n">layer</span> <span class="n">mask</span><span class="o">=</span><span class="n">Select</span><span class="p">(</span><span class="n">l</span><span class="p">,{</span><span class="s">&quot;3&quot;</span><span class="p">});</span>  <span class="c1">// UnCat [3] mask</span>
    <span class="c1">// Both, image and mask, have the same augmentation</span>

    <span class="c1">// Define DA model inputs</span>
    <span class="n">model</span> <span class="n">danet</span><span class="o">=</span><span class="n">Model</span><span class="p">({</span><span class="n">in1</span><span class="p">,</span><span class="n">in2</span><span class="p">},{});</span>

    <span class="c1">// Build model for DA</span>
    <span class="n">build</span><span class="p">(</span><span class="n">danet</span><span class="p">);</span>
    <span class="n">toGPU</span><span class="p">(</span><span class="n">danet</span><span class="p">,</span><span class="s">&quot;low_mem&quot;</span><span class="p">);</span>   <span class="c1">// only in GPU 0 with low_mem setup</span>
    <span class="n">summary</span><span class="p">(</span><span class="n">danet</span><span class="p">);</span>

    <span class="c1">//////////////////////////////////////////////////////////////</span>
    <span class="c1">// Build SegNet</span>
    <span class="n">layer</span> <span class="n">in</span><span class="o">=</span><span class="n">Input</span><span class="p">({</span><span class="mi">3</span><span class="p">,</span><span class="mi">512</span><span class="p">,</span><span class="mi">512</span><span class="p">});</span>
    <span class="n">layer</span> <span class="n">out</span><span class="o">=</span><span class="n">Sigmoid</span><span class="p">(</span><span class="n">UNetWithPadding</span><span class="p">(</span><span class="n">in</span><span class="p">));</span>
    <span class="n">model</span> <span class="n">segnet</span><span class="o">=</span><span class="n">Model</span><span class="p">({</span><span class="n">in</span><span class="p">},{</span><span class="n">out</span><span class="p">});</span>
    <span class="n">build</span><span class="p">(</span><span class="n">segnet</span><span class="p">,</span>
          <span class="n">adam</span><span class="p">(</span><span class="mf">0.00001</span><span class="p">),</span> <span class="c1">// Optimizer</span>
          <span class="p">{</span><span class="s">&quot;mse&quot;</span><span class="p">},</span> <span class="c1">// Losses</span>
          <span class="p">{</span><span class="s">&quot;mse&quot;</span><span class="p">},</span> <span class="c1">// Metrics</span>
            <span class="n">CS_GPU</span><span class="p">({</span><span class="mi">1</span><span class="p">},</span> <span class="s">&quot;low_mem&quot;</span><span class="p">)</span>
          <span class="c1">//CS_CPU(-1)</span>
    <span class="p">);</span>
    <span class="c1">// Train on multi-gpu with sync weights every 100 batches:</span>
<span class="c1">//  toGPU(segnet,{1},100,&quot;low_mem&quot;); // In two gpus, syncronize every 100 batches, low_mem setup</span>
    <span class="n">summary</span><span class="p">(</span><span class="n">segnet</span><span class="p">);</span>
    <span class="n">plot</span><span class="p">(</span><span class="n">segnet</span><span class="p">,</span><span class="s">&quot;segnet.pdf&quot;</span><span class="p">);</span>

    <span class="c1">//////////////////////////////////////////////////////////////</span>
    <span class="c1">// Load and preprocess training data</span>
    <span class="n">cout</span><span class="o">&lt;&lt;</span><span class="s">&quot;Reading train numpy</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">;</span>
    <span class="n">Tensor</span><span class="o">*</span> <span class="n">x_train</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;drive_trX.bin&quot;</span><span class="p">);</span>
    <span class="n">x_train</span><span class="o">-&gt;</span><span class="n">info</span><span class="p">();</span>
    <span class="n">x_train</span><span class="o">-&gt;</span><span class="n">div_</span><span class="p">(</span><span class="mf">255.0f</span><span class="p">);</span>
    <span class="c1">//permute</span>

    <span class="n">cout</span><span class="o">&lt;&lt;</span><span class="s">&quot;Reading test numpy</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">;</span>
    <span class="n">Tensor</span><span class="o">*</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;drive_trY.bin&quot;</span><span class="p">);</span>
    <span class="n">y_train</span><span class="o">-&gt;</span><span class="n">info</span><span class="p">();</span>
    <span class="n">y_train</span><span class="o">-&gt;</span><span class="n">div_</span><span class="p">(</span><span class="mf">255.0f</span><span class="p">);</span>

    <span class="n">Tensor</span><span class="o">*</span> <span class="n">xbatch</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Tensor</span><span class="p">({</span><span class="n">batch_size</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">584</span><span class="p">,</span><span class="mi">584</span><span class="p">});</span>
    <span class="n">Tensor</span><span class="o">*</span> <span class="n">ybatch</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Tensor</span><span class="p">({</span><span class="n">batch_size</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">584</span><span class="p">,</span><span class="mi">584</span><span class="p">});</span>


    <span class="c1">//////////////////////////////////////////////////////////////</span>
    <span class="c1">// Training</span>
    <span class="kt">int</span> <span class="n">num_batches</span><span class="o">=</span><span class="mi">1000</span><span class="p">;</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="n">epochs</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">reset_loss</span><span class="p">(</span><span class="n">segnet</span><span class="p">);</span>
        <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">j</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">j</span><span class="o">&lt;</span><span class="n">num_batches</span><span class="p">;</span><span class="n">j</span><span class="o">++</span><span class="p">)</span>  <span class="p">{</span>

            <span class="n">next_batch</span><span class="p">({</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">},{</span><span class="n">xbatch</span><span class="p">,</span><span class="n">ybatch</span><span class="p">});</span>

            <span class="n">Tensor</span><span class="o">*</span> <span class="n">xout</span> <span class="o">=</span> <span class="n">xbatch</span><span class="o">-&gt;</span><span class="n">select</span><span class="p">({</span><span class="s">&quot;0&quot;</span><span class="p">});</span>
            <span class="n">xout</span><span class="o">-&gt;</span><span class="n">mult_</span><span class="p">(</span><span class="mf">255.0f</span><span class="p">);</span>
            <span class="n">xout</span><span class="o">-&gt;</span><span class="n">save</span><span class="p">(</span><span class="s">&quot;./0.tr_out_prev.jpg&quot;</span><span class="p">);</span>
            <span class="k">delete</span> <span class="n">xout</span><span class="p">;</span>

            <span class="n">Tensor</span><span class="o">*</span> <span class="n">yout</span> <span class="o">=</span> <span class="n">ybatch</span><span class="o">-&gt;</span><span class="n">select</span><span class="p">({</span><span class="s">&quot;0&quot;</span><span class="p">});</span>
            <span class="n">yout</span><span class="o">-&gt;</span><span class="n">mult_</span><span class="p">(</span><span class="mf">255.0f</span><span class="p">);</span>
            <span class="n">yout</span><span class="o">-&gt;</span><span class="n">save</span><span class="p">(</span><span class="s">&quot;./0.ts_out_prev.jpg&quot;</span><span class="p">);</span>
            <span class="k">delete</span> <span class="n">yout</span><span class="p">;</span>

            <span class="c1">// DA</span>
            <span class="n">forward</span><span class="p">(</span><span class="n">danet</span><span class="p">,</span> <span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span> <span class="o">*&gt;</span><span class="p">{</span><span class="n">xbatch</span><span class="p">,</span> <span class="n">ybatch</span><span class="p">});</span>

            <span class="c1">// get COPIES of tensors from DA</span>
            <span class="n">Tensor</span><span class="o">*</span> <span class="n">xbatch_da</span> <span class="o">=</span> <span class="n">getOutput</span><span class="p">(</span><span class="n">img</span><span class="p">);</span>
            <span class="n">Tensor</span><span class="o">*</span> <span class="n">ybatch_da</span> <span class="o">=</span> <span class="n">getOutput</span><span class="p">(</span><span class="n">mask</span><span class="p">);</span>

            <span class="c1">// SegNet</span>
            <span class="n">train_batch</span><span class="p">(</span><span class="n">segnet</span><span class="p">,</span> <span class="p">{</span><span class="n">xbatch_da</span><span class="p">},{</span><span class="n">ybatch_da</span><span class="p">});</span>

            <span class="n">print_loss</span><span class="p">(</span><span class="n">segnet</span><span class="p">,</span> <span class="n">j</span><span class="p">);</span>
            <span class="c1">// printf(&quot;  sum=%f&quot;,yout-&gt;sum());</span>
            <span class="n">printf</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\r</span><span class="s">&quot;</span><span class="p">);</span>

            <span class="k">delete</span> <span class="n">xbatch_da</span><span class="p">;</span>
            <span class="k">delete</span> <span class="n">ybatch_da</span><span class="p">;</span>

            <span class="c1">// We should use &quot;mult_(255.0f)&quot; but with normalize we can stretch its contrast and see results faster</span>
            <span class="n">Tensor</span><span class="o">*</span> <span class="n">yout2</span> <span class="o">=</span> <span class="n">getOutput</span><span class="p">(</span><span class="n">out</span><span class="p">);</span>
            <span class="n">yout2</span> <span class="o">=</span> <span class="n">yout2</span><span class="o">-&gt;</span><span class="n">select</span><span class="p">({</span><span class="s">&quot;0&quot;</span><span class="p">});</span>
            <span class="n">yout2</span><span class="o">-&gt;</span><span class="n">normalize_</span><span class="p">(</span><span class="mf">0.0f</span><span class="p">,</span> <span class="mf">255.0f</span><span class="p">);</span>
            <span class="n">yout2</span><span class="o">-&gt;</span><span class="n">save</span><span class="p">(</span><span class="s">&quot;./out.jpg&quot;</span><span class="p">);</span>
            <span class="k">delete</span> <span class="n">yout2</span><span class="p">;</span>
        <span class="p">}</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
    <span class="p">}</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="training-a-rnn">
<h2>Training a RNN<a class="headerlink" href="#training-a-rnn" title="Permalink to this headline">¶</a></h2>
<p>This example trains and evaluates an Embedding and RNN using IMBD dataset. <a class="reference external" href="https://github.com/deephealthproject/eddl/blob/master/examples/nn/4_NLP/1_nlp_sentiment_rnn.cpp">[source]</a></p>
<img alt="../_images/rnn.png" src="../_images/rnn.png" />
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span> <span class="cpf">&lt;cstdio&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;cstdlib&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp"></span>

<span class="cp">#include</span> <span class="cpf">&quot;eddl/apis/eddl.h&quot;</span><span class="cp"></span>


<span class="k">using</span> <span class="k">namespace</span> <span class="n">eddl</span><span class="p">;</span>

<span class="c1">//////////////////////////////////</span>
<span class="c1">// Embeding+RNN</span>
<span class="c1">// using imdb preprocessed from keras</span>
<span class="c1">// 2000 words</span>
<span class="c1">//////////////////////////////////</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// Download Imdb</span>
    <span class="n">download_imdb_2000</span><span class="p">();</span>

    <span class="c1">// Settings</span>
    <span class="kt">int</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span><span class="p">;</span>

    <span class="kt">int</span> <span class="n">length</span><span class="o">=</span><span class="mi">250</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">embdim</span><span class="o">=</span><span class="mi">32</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">vocsize</span><span class="o">=</span> <span class="mi">2000</span><span class="p">;</span>

    <span class="c1">// Define network</span>
    <span class="n">layer</span> <span class="n">in</span> <span class="o">=</span> <span class="n">Input</span><span class="p">({</span><span class="mi">1</span><span class="p">});</span> <span class="c1">//1 word</span>
    <span class="n">layer</span> <span class="n">l</span> <span class="o">=</span> <span class="n">in</span><span class="p">;</span>

    <span class="n">layer</span> <span class="n">lE</span> <span class="o">=</span> <span class="n">RandomUniform</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">vocsize</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span><span class="n">embdim</span><span class="p">),</span><span class="mf">-0.05</span><span class="p">,</span><span class="mf">0.05</span><span class="p">);</span>

    <span class="n">l</span> <span class="o">=</span> <span class="n">RNN</span><span class="p">(</span><span class="n">lE</span><span class="p">,</span><span class="mi">32</span><span class="p">);</span>
    <span class="n">l</span> <span class="o">=</span> <span class="n">ReLu</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="mi">256</span><span class="p">));</span>


    <span class="n">layer</span> <span class="n">out</span> <span class="o">=</span> <span class="n">Sigmoid</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="mi">1</span><span class="p">));</span>
    <span class="n">model</span> <span class="n">net</span> <span class="o">=</span> <span class="n">Model</span><span class="p">({</span><span class="n">in</span><span class="p">},</span> <span class="p">{</span><span class="n">out</span><span class="p">});</span>

    <span class="c1">// dot from graphviz should be installed:</span>
    <span class="n">plot</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="s">&quot;model.pdf&quot;</span><span class="p">);</span>

    <span class="n">optimizer</span> <span class="n">opt</span><span class="o">=</span><span class="n">adam</span><span class="p">(</span><span class="mf">0.001</span><span class="p">);</span>
    <span class="c1">//opt-&gt;set_clip_val(0.01);</span>

    <span class="c1">// Build model</span>
    <span class="n">build</span><span class="p">(</span><span class="n">net</span><span class="p">,</span>
          <span class="n">opt</span><span class="p">,</span> <span class="c1">// Optimizer</span>
          <span class="p">{</span><span class="s">&quot;binary_cross_entropy&quot;</span><span class="p">},</span> <span class="c1">// Losses</span>
          <span class="p">{</span><span class="s">&quot;binary_accuracy&quot;</span><span class="p">},</span> <span class="c1">// Metrics</span>
          <span class="n">CS_GPU</span><span class="p">({</span><span class="mi">1</span><span class="p">})</span> <span class="c1">// one GPU</span>
          <span class="c1">//CS_GPU({1,1},100) // two GPU with weight sync every 100 batches</span>
<span class="c1">//          CS_CPU()</span>
    <span class="p">);</span>

    <span class="c1">// View model</span>
    <span class="n">summary</span><span class="p">(</span><span class="n">net</span><span class="p">);</span>

    <span class="c1">// Load dataset</span>
    <span class="n">Tensor</span><span class="o">*</span> <span class="n">x_train</span><span class="o">=</span><span class="n">Tensor</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;imdb_2000_trX.bin&quot;</span><span class="p">);</span>
    <span class="n">Tensor</span><span class="o">*</span> <span class="n">y_train</span><span class="o">=</span><span class="n">Tensor</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;imdb_2000_trY.bin&quot;</span><span class="p">);</span>

    <span class="n">Tensor</span><span class="o">*</span> <span class="n">x_test</span><span class="o">=</span><span class="n">Tensor</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;imdb_2000_tsX.bin&quot;</span><span class="p">);</span>
    <span class="n">Tensor</span><span class="o">*</span> <span class="n">y_test</span><span class="o">=</span><span class="n">Tensor</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;imdb_2000_tsY.bin&quot;</span><span class="p">);</span>

    <span class="n">x_train</span><span class="o">-&gt;</span><span class="n">reshape_</span><span class="p">({</span><span class="n">x_train</span><span class="o">-&gt;</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">length</span><span class="p">,</span><span class="mi">1</span><span class="p">});</span> <span class="c1">//batch x timesteps x input_dim</span>
    <span class="n">x_test</span><span class="o">-&gt;</span><span class="n">reshape_</span><span class="p">({</span><span class="n">x_test</span><span class="o">-&gt;</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">length</span><span class="p">,</span><span class="mi">1</span><span class="p">});</span> <span class="c1">//batch x timesteps x input_dim</span>

    <span class="n">y_train</span><span class="o">-&gt;</span><span class="n">reshape_</span><span class="p">({</span><span class="n">y_train</span><span class="o">-&gt;</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">});</span> <span class="c1">//batch x timesteps x input_dim</span>
    <span class="n">y_test</span><span class="o">-&gt;</span><span class="n">reshape_</span><span class="p">({</span><span class="n">y_test</span><span class="o">-&gt;</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">});</span> <span class="c1">//batch x timesteps x input_dim</span>

    <span class="c1">// Train model</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="n">epochs</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">fit</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="p">{</span><span class="n">x_train</span><span class="p">},</span> <span class="p">{</span><span class="n">y_train</span><span class="p">},</span> <span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
      <span class="n">evaluate</span><span class="p">(</span><span class="n">net</span><span class="p">,{</span><span class="n">x_test</span><span class="p">},{</span><span class="n">y_test</span><span class="p">});</span>
    <span class="p">}</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="training-a-lstm">
<h2>Training a LSTM<a class="headerlink" href="#training-a-lstm" title="Permalink to this headline">¶</a></h2>
<p>This example trains and evaluates an Embedding and LSTM using IMBD dataset. <a class="reference external" href="https://github.com/deephealthproject/eddl/blob/master/examples/nn/4_NLP/2_nlp_sentiment_lstm.cpp">[source]</a></p>
<img alt="../_images/lstm.png" src="../_images/lstm.png" />
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span> <span class="cpf">&lt;cstdio&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;cstdlib&gt;</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp"></span>

<span class="cp">#include</span> <span class="cpf">&quot;eddl/apis/eddl.h&quot;</span><span class="cp"></span>


<span class="k">using</span> <span class="k">namespace</span> <span class="n">eddl</span><span class="p">;</span>

<span class="c1">//////////////////////////////////</span>
<span class="c1">// Embeding+LSTM</span>
<span class="c1">// using imdb preprocessed from keras</span>
<span class="c1">// 2000 words</span>
<span class="c1">//////////////////////////////////</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// Download Imdb</span>
    <span class="n">download_imdb_2000</span><span class="p">();</span>

    <span class="c1">// Settings</span>
    <span class="kt">int</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span><span class="p">;</span>

    <span class="kt">int</span> <span class="n">length</span><span class="o">=</span><span class="mi">250</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">embdim</span><span class="o">=</span><span class="mi">32</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">vocsize</span><span class="o">=</span><span class="mi">2000</span><span class="p">;</span>

    <span class="c1">// Define network</span>
    <span class="n">layer</span> <span class="n">in</span> <span class="o">=</span> <span class="n">Input</span><span class="p">({</span><span class="mi">1</span><span class="p">});</span> <span class="c1">//1 word</span>
    <span class="n">layer</span> <span class="n">l</span> <span class="o">=</span> <span class="n">in</span><span class="p">;</span>

    <span class="n">layer</span> <span class="n">lE</span> <span class="o">=</span> <span class="n">RandomUniform</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">vocsize</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span><span class="n">embdim</span><span class="p">),</span><span class="mf">-0.05</span><span class="p">,</span><span class="mf">0.05</span><span class="p">);</span>

    <span class="n">l</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="n">lE</span><span class="p">,</span><span class="mi">32</span><span class="p">);</span>
    <span class="n">l</span> <span class="o">=</span> <span class="n">ReLu</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="mi">256</span><span class="p">));</span>

    <span class="n">layer</span> <span class="n">out</span> <span class="o">=</span> <span class="n">Sigmoid</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="mi">1</span><span class="p">));</span>
    <span class="n">model</span> <span class="n">net</span> <span class="o">=</span> <span class="n">Model</span><span class="p">({</span><span class="n">in</span><span class="p">},</span> <span class="p">{</span><span class="n">out</span><span class="p">});</span>

    <span class="c1">// dot from graphviz should be installed:</span>
    <span class="n">plot</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="s">&quot;model.pdf&quot;</span><span class="p">);</span>

    <span class="n">optimizer</span> <span class="n">opt</span><span class="o">=</span><span class="n">adam</span><span class="p">(</span><span class="mf">0.001</span><span class="p">);</span>
    <span class="c1">//opt-&gt;set_clip_val(0.01);</span>

    <span class="c1">// Build model</span>
    <span class="n">build</span><span class="p">(</span><span class="n">net</span><span class="p">,</span>
          <span class="n">opt</span><span class="p">,</span> <span class="c1">// Optimizer</span>
          <span class="p">{</span><span class="s">&quot;binary_cross_entropy&quot;</span><span class="p">},</span> <span class="c1">// Losses</span>
          <span class="p">{</span><span class="s">&quot;binary_accuracy&quot;</span><span class="p">},</span> <span class="c1">// Metrics</span>
          <span class="n">CS_GPU</span><span class="p">({</span><span class="mi">1</span><span class="p">})</span> <span class="c1">// one GPU</span>
          <span class="c1">//CS_GPU({1,1},100) // two GPU with weight sync every 100 batches</span>
<span class="c1">//          CS_CPU()</span>
    <span class="p">);</span>

    <span class="c1">// View model</span>
    <span class="n">summary</span><span class="p">(</span><span class="n">net</span><span class="p">);</span>

    <span class="c1">// Load dataset</span>
    <span class="n">Tensor</span><span class="o">*</span> <span class="n">x_train</span><span class="o">=</span><span class="n">Tensor</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;imdb_2000_trX.bin&quot;</span><span class="p">);</span>
    <span class="n">Tensor</span><span class="o">*</span> <span class="n">y_train</span><span class="o">=</span><span class="n">Tensor</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;imdb_2000_trY.bin&quot;</span><span class="p">);</span>
    <span class="n">Tensor</span><span class="o">*</span> <span class="n">x_test</span><span class="o">=</span><span class="n">Tensor</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;imdb_2000_tsX.bin&quot;</span><span class="p">);</span>
    <span class="n">Tensor</span><span class="o">*</span> <span class="n">y_test</span><span class="o">=</span><span class="n">Tensor</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;imdb_2000_tsY.bin&quot;</span><span class="p">);</span>

    <span class="n">x_train</span><span class="o">-&gt;</span><span class="n">reshape_</span><span class="p">({</span><span class="n">x_train</span><span class="o">-&gt;</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">length</span><span class="p">,</span><span class="mi">1</span><span class="p">});</span> <span class="c1">//batch x timesteps x input_dim</span>
    <span class="n">x_test</span><span class="o">-&gt;</span><span class="n">reshape_</span><span class="p">({</span><span class="n">x_test</span><span class="o">-&gt;</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">length</span><span class="p">,</span><span class="mi">1</span><span class="p">});</span> <span class="c1">//batch x timesteps x input_dim</span>

    <span class="n">y_train</span><span class="o">-&gt;</span><span class="n">reshape_</span><span class="p">({</span><span class="n">y_train</span><span class="o">-&gt;</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">});</span> <span class="c1">//batch x timesteps x input_dim</span>
    <span class="n">y_test</span><span class="o">-&gt;</span><span class="n">reshape_</span><span class="p">({</span><span class="n">y_test</span><span class="o">-&gt;</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">});</span> <span class="c1">//batch x timesteps x input_dim</span>

    <span class="c1">// Train model</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="n">epochs</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">fit</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="p">{</span><span class="n">x_train</span><span class="p">},</span> <span class="p">{</span><span class="n">y_train</span><span class="p">},</span> <span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
      <span class="c1">//evaluate(net,{x_test},{y_test});</span>
    <span class="p">}</span>

<span class="p">}</span>
</pre></div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../videotutorials/developers.html" class="btn btn-neutral float-right" title="Development" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="intermediate.html" class="btn btn-neutral float-left" title="Intermediate models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, EDDL

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>