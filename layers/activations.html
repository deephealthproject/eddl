<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Activations &mdash; EDDL  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/tabs.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Data augmentation" href="data_augmentation.html" />
    <link rel="prev" title="Auxiliar Layers" href="auxiliar.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #185070" >
            <a href="../index.html">
            <img src="../_static/logo-eddl-small-white.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intro/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/build-options.html">Build and configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/troubleshoot.html">Troubleshoot</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Get started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../usage/getting_started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../usage/intermediate.html">Intermediate models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../usage/advanced.html">Advanced models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../usage/pretrained.html">Pretrained models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Videotutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../videotutorials/developers.html">Development</a></li>
<li class="toctree-l1"><a class="reference internal" href="../videotutorials/usage.html">Showcase</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Layers</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="core.html">Core</a></li>
<li class="toctree-l1"><a class="reference internal" href="auxiliar.html">Auxiliar Layers</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Activations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#softmax">Softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sigmoid">Sigmoid</a></li>
<li class="toctree-l2"><a class="reference internal" href="#relu">ReLu</a></li>
<li class="toctree-l2"><a class="reference internal" href="#thresholded-relu">Thresholded ReLu</a></li>
<li class="toctree-l2"><a class="reference internal" href="#leaky-relu">Leaky ReLu</a></li>
<li class="toctree-l2"><a class="reference internal" href="#elu">ELu</a></li>
<li class="toctree-l2"><a class="reference internal" href="#selu">SeLu</a></li>
<li class="toctree-l2"><a class="reference internal" href="#exponential">Exponential</a></li>
<li class="toctree-l2"><a class="reference internal" href="#softplus">Softplus</a></li>
<li class="toctree-l2"><a class="reference internal" href="#softsign">Softsign</a></li>
<li class="toctree-l2"><a class="reference internal" href="#linear">Linear</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tanh">Tanh</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="data_augmentation.html">Data augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_transformation.html">Data transformation</a></li>
<li class="toctree-l1"><a class="reference internal" href="convolutional.html">Convolutions</a></li>
<li class="toctree-l1"><a class="reference internal" href="noise.html">Noise Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="pooling.html">Pooling</a></li>
<li class="toctree-l1"><a class="reference internal" href="normalization.html">Normalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="merge.html">Merge</a></li>
<li class="toctree-l1"><a class="reference internal" href="generators.html">Generators</a></li>
<li class="toctree-l1"><a class="reference internal" href="operators.html">Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="reduction.html">Reduce</a></li>
<li class="toctree-l1"><a class="reference internal" href="rnn.html">Recurrent</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../model/model.html">Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model/onnx.html">Save and load ONNX models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../training/coarse.html">Coarse training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training/fine_grained.html">Fine-grained training</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Test &amp; Score</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../test_score/test_score.html">Test &amp; Score</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Bundle</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../bundle/losses.html">Losses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bundle/metrics.html">Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bundle/regularizers.html">Regularizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bundle/initializers.html">Initializers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bundle/optimizers.html">Optimizers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Computing Services</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../bundle/computing_service.html">CPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bundle/computing_service.html#gpu">GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bundle/computing_service.html#fpga">FPGA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bundle/computing_service.html#compss">COMPSS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bundle/computing_service.html#serialization">Serialization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Zoo</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../models_zoo/classification.html">Classification</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Datasets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../datasets/classification.html">Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/segmentation.html">Segmentation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tensor</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tensor/create.html">Creation Routines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor/manipulation.html">Manipulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor/image.html">Image operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor/indexing.html">Indexing &amp; Sorting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor/input_output.html">Input/Output Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor/linear_algebra.html">Linear algebra</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor/logic_functions.html">Logic functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor/math.html">Mathematical functions</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #185070" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">EDDL</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Activations</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/layers/activations.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="activations">
<h1>Activations<a class="headerlink" href="#activations" title="Permalink to this headline"></a></h1>
<div class="section" id="softmax">
<h2>Softmax<a class="headerlink" href="#softmax" title="Permalink to this headline"></a></h2>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N4eddl7SoftmaxE5layeri6string">
<span id="_CPPv3N4eddl7SoftmaxE5layeri6string"></span><span id="_CPPv2N4eddl7SoftmaxE5layeri6string"></span><span id="eddl::Softmax__layer.i.string"></span><span class="target" id="namespaceeddl_1a9910e03e154a92592ba7e95aeb6b5ba0"></span><span class="n"><span class="pre">layer</span></span><span class="w"> </span><span class="sig-prename descclassname"><span class="n"><span class="pre">eddl</span></span><span class="p"><span class="pre">::</span></span></span><span class="sig-name descname"><span class="n"><span class="pre">Softmax</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">layer</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">parent</span></span>, <span class="kt"><span class="pre">int</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">axis</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="o"><span class="pre">-</span></span><span class="m"><span class="pre">1</span></span>, <span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">name</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="s"><span class="pre">&quot;&quot;</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N4eddl7SoftmaxE5layeri6string" title="Permalink to this definition"></a><br /></dt>
<dd><p>Applies a Jacobian Softmax activation function to the given layer. </p>
<p><dl class="simple">
<dt><strong>See</strong></dt><dd><p><a class="reference external" href="https://en.wikipedia.org/wiki/Softmax_function">https://en.wikipedia.org/wiki/Softmax_function</a></p>
</dd>
</dl>
</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parent</strong> – Parent layer </p></li>
<li><p><strong>axis</strong> – Dimension in which to operate. Default -1, which uses the last axis </p></li>
<li><p><strong>name</strong> – Name of the layer </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output of Softmax transformation </p>
</dd>
</dl>
</dd></dl>

<p>The Softmax activation function is: <code class="docutils literal notranslate"><span class="pre">softmax(x)</span> <span class="pre">=</span> <span class="pre">exp(x)</span> <span class="pre">/</span> <span class="pre">reduce_sum(exp(x))</span></code></p>
<p>Example:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Softmax</span><span class="p">(</span><span class="n">l</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
</div>
<div class="section" id="sigmoid">
<h2>Sigmoid<a class="headerlink" href="#sigmoid" title="Permalink to this headline"></a></h2>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N4eddl7SigmoidE5layer6string">
<span id="_CPPv3N4eddl7SigmoidE5layer6string"></span><span id="_CPPv2N4eddl7SigmoidE5layer6string"></span><span id="eddl::Sigmoid__layer.string"></span><span class="target" id="namespaceeddl_1a0a00e2ca0f84544a01e296bc3ebaeeec"></span><span class="n"><span class="pre">layer</span></span><span class="w"> </span><span class="sig-prename descclassname"><span class="n"><span class="pre">eddl</span></span><span class="p"><span class="pre">::</span></span></span><span class="sig-name descname"><span class="n"><span class="pre">Sigmoid</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">layer</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">parent</span></span>, <span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">name</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="s"><span class="pre">&quot;&quot;</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N4eddl7SigmoidE5layer6string" title="Permalink to this definition"></a><br /></dt>
<dd><p>Applies a Sigmoid activation function to the given layer. </p>
<p><dl class="simple">
<dt><strong>See</strong></dt><dd><p><a class="reference external" href="https://en.wikipedia.org/wiki/Sigmoid_function">https://en.wikipedia.org/wiki/Sigmoid_function</a></p>
</dd>
</dl>
</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parent</strong> – Parent layer </p></li>
<li><p><strong>name</strong> – Name of the layer </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output of Sigmoid activation </p>
</dd>
</dl>
</dd></dl>

<p>The Sigmoid activation function is: <code class="docutils literal notranslate"><span class="pre">sigmoid(x)</span> <span class="pre">=</span> <span class="pre">1</span> <span class="pre">/</span> <span class="pre">(1</span> <span class="pre">+</span> <span class="pre">exp(-x))</span></code></p>
<p>Example:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Sigmoid</span><span class="p">(</span><span class="n">l</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
</div>
<div class="section" id="relu">
<h2>ReLu<a class="headerlink" href="#relu" title="Permalink to this headline"></a></h2>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N4eddl4ReLuE5layer6string">
<span id="_CPPv3N4eddl4ReLuE5layer6string"></span><span id="_CPPv2N4eddl4ReLuE5layer6string"></span><span id="eddl::ReLu__layer.string"></span><span class="target" id="namespaceeddl_1ad57546f5a5bd2cf98630475bcef9cd1d"></span><span class="n"><span class="pre">layer</span></span><span class="w"> </span><span class="sig-prename descclassname"><span class="n"><span class="pre">eddl</span></span><span class="p"><span class="pre">::</span></span></span><span class="sig-name descname"><span class="n"><span class="pre">ReLu</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">layer</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">parent</span></span>, <span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">name</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="s"><span class="pre">&quot;&quot;</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N4eddl4ReLuE5layer6string" title="Permalink to this definition"></a><br /></dt>
<dd><p>Applies a Rectified Linear Unit activation function to the given layer. </p>
<p><dl class="simple">
<dt><strong>See</strong></dt><dd><p><a class="reference external" href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)">https://en.wikipedia.org/wiki/Rectifier_(neural_networks)</a></p>
</dd>
</dl>
</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parent</strong> – Parent layer </p></li>
<li><p><strong>name</strong> – Name of the layer </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output of ReLu activation </p>
</dd>
</dl>
</dd></dl>

<p>The ReLu activation function is:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">x</span> <span class="pre">&gt;</span> <span class="pre">0:</span> <span class="pre">relu(x)</span> <span class="pre">=</span> <span class="pre">x</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">else:</span> <span class="pre">relu(x)</span> <span class="pre">=</span> <span class="pre">0</span></code></p></li>
</ul>
<p>Example:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ReLu</span><span class="p">(</span><span class="n">l</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
</div>
<div class="section" id="thresholded-relu">
<h2>Thresholded ReLu<a class="headerlink" href="#thresholded-relu" title="Permalink to this headline"></a></h2>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N4eddl15ThresholdedReLuE5layerf6string">
<span id="_CPPv3N4eddl15ThresholdedReLuE5layerf6string"></span><span id="_CPPv2N4eddl15ThresholdedReLuE5layerf6string"></span><span id="eddl::ThresholdedReLu__layer.float.string"></span><span class="target" id="namespaceeddl_1a4cefb5431bc97c025ddbc44f69046385"></span><span class="n"><span class="pre">layer</span></span><span class="w"> </span><span class="sig-prename descclassname"><span class="n"><span class="pre">eddl</span></span><span class="p"><span class="pre">::</span></span></span><span class="sig-name descname"><span class="n"><span class="pre">ThresholdedReLu</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">layer</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">parent</span></span>, <span class="kt"><span class="pre">float</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">alpha</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">1.0</span></span>, <span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">name</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="s"><span class="pre">&quot;&quot;</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N4eddl15ThresholdedReLuE5layerf6string" title="Permalink to this definition"></a><br /></dt>
<dd><p>Applies the Thresholded version of a Rectified Linear Unit activation function to the given layer. </p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parent</strong> – Parent layer </p></li>
<li><p><strong>alpha</strong> – Threshold value </p></li>
<li><p><strong>name</strong> – Name of the layer </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output of Thresholded ReLu activation </p>
</dd>
</dl>
</dd></dl>

<p>The Thresholded ReLu activation function is:</p>
<ul class="simple">
<li><p>if <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">&gt;</span> <span class="pre">alpha</span></code>: <code class="docutils literal notranslate"><span class="pre">threshdolded_relu(x)</span> <span class="pre">=</span> <span class="pre">x</span></code></p></li>
<li><p>else: <code class="docutils literal notranslate"><span class="pre">thresholded_relu(x)</span> <span class="pre">=</span> <span class="pre">0</span></code></p></li>
</ul>
<p>Example:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ThresholdedReLu</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
</div>
<div class="section" id="leaky-relu">
<h2>Leaky ReLu<a class="headerlink" href="#leaky-relu" title="Permalink to this headline"></a></h2>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N4eddl9LeakyReLuE5layerf6string">
<span id="_CPPv3N4eddl9LeakyReLuE5layerf6string"></span><span id="_CPPv2N4eddl9LeakyReLuE5layerf6string"></span><span id="eddl::LeakyReLu__layer.float.string"></span><span class="target" id="namespaceeddl_1a76499622d283a9bba29e97718987a847"></span><span class="n"><span class="pre">layer</span></span><span class="w"> </span><span class="sig-prename descclassname"><span class="n"><span class="pre">eddl</span></span><span class="p"><span class="pre">::</span></span></span><span class="sig-name descname"><span class="n"><span class="pre">LeakyReLu</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">layer</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">parent</span></span>, <span class="kt"><span class="pre">float</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">alpha</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">0.01</span></span>, <span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">name</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="s"><span class="pre">&quot;&quot;</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N4eddl9LeakyReLuE5layerf6string" title="Permalink to this definition"></a><br /></dt>
<dd><p>Applies the Leaky version of a Rectified Linear Unit activation function to the given layer. </p>
<p><dl class="simple">
<dt><strong>See</strong></dt><dd><p><a class="reference external" href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)#Leaky_ReLUs">https://en.wikipedia.org/wiki/Rectifier_(neural_networks)#Leaky_ReLUs</a></p>
</dd>
</dl>
</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parent</strong> – Parent layer </p></li>
<li><p><strong>alpha</strong> – Negative slope coefficient </p></li>
<li><p><strong>name</strong> – Name of the layer </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output of Leaky ReLu activation </p>
</dd>
</dl>
</dd></dl>

<p>The Leaky ReLu activation function is:</p>
<ul class="simple">
<li><p>if <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">&gt;</span> <span class="pre">0</span></code>: <code class="docutils literal notranslate"><span class="pre">leaky_relu(x)</span> <span class="pre">=</span> <span class="pre">x</span></code></p></li>
<li><p>else: <code class="docutils literal notranslate"><span class="pre">leaky_relu(x)</span> <span class="pre">=</span> <span class="pre">alpha</span> <span class="pre">*</span> <span class="pre">x</span></code></p></li>
</ul>
<p>Example:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">LeakyReLu</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="w"> </span><span class="mf">0.01</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
</div>
<div class="section" id="elu">
<h2>ELu<a class="headerlink" href="#elu" title="Permalink to this headline"></a></h2>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N4eddl3EluE5layerf6string">
<span id="_CPPv3N4eddl3EluE5layerf6string"></span><span id="_CPPv2N4eddl3EluE5layerf6string"></span><span id="eddl::Elu__layer.float.string"></span><span class="target" id="namespaceeddl_1ad3f5c18cab381400cced4c3f9f0fc16b"></span><span class="n"><span class="pre">layer</span></span><span class="w"> </span><span class="sig-prename descclassname"><span class="n"><span class="pre">eddl</span></span><span class="p"><span class="pre">::</span></span></span><span class="sig-name descname"><span class="n"><span class="pre">Elu</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">layer</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">parent</span></span>, <span class="kt"><span class="pre">float</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">alpha</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">1.0</span></span>, <span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">name</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="s"><span class="pre">&quot;&quot;</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N4eddl3EluE5layerf6string" title="Permalink to this definition"></a><br /></dt>
<dd><p>Applies the Exponential Linear Unit activation function to the given layer. </p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parent</strong> – Parent layer </p></li>
<li><p><strong>alpha</strong> – ELu coefficient </p></li>
<li><p><strong>name</strong> – Name of the layer </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output of ELu activation </p>
</dd>
</dl>
</dd></dl>

<p>The ELu activation function is:</p>
<ul class="simple">
<li><p>if <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">&gt;</span> <span class="pre">0</span></code>: <code class="docutils literal notranslate"><span class="pre">elu(x)</span> <span class="pre">=</span> <span class="pre">x</span></code></p></li>
<li><p>else: <code class="docutils literal notranslate"><span class="pre">elu(x)</span> <span class="pre">=</span> <span class="pre">alpha</span> <span class="pre">*</span>&#160; <span class="pre">(exp(x)</span> <span class="pre">-</span> <span class="pre">1)</span></code></p></li>
</ul>
<p>Example:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Elu</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
</div>
<div class="section" id="selu">
<h2>SeLu<a class="headerlink" href="#selu" title="Permalink to this headline"></a></h2>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N4eddl4SeluE5layer6string">
<span id="_CPPv3N4eddl4SeluE5layer6string"></span><span id="_CPPv2N4eddl4SeluE5layer6string"></span><span id="eddl::Selu__layer.string"></span><span class="target" id="namespaceeddl_1a951161b688b1cda08c3559d35eaedc26"></span><span class="n"><span class="pre">layer</span></span><span class="w"> </span><span class="sig-prename descclassname"><span class="n"><span class="pre">eddl</span></span><span class="p"><span class="pre">::</span></span></span><span class="sig-name descname"><span class="n"><span class="pre">Selu</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">layer</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">parent</span></span>, <span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">name</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="s"><span class="pre">&quot;&quot;</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N4eddl4SeluE5layer6string" title="Permalink to this definition"></a><br /></dt>
<dd><p>Applies the Scaled Exponential Linear Unit activation function to the given layer. </p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parent</strong> – Parent layer </p></li>
<li><p><strong>name</strong> – Name of the layer </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output of Selu activation </p>
</dd>
</dl>
</dd></dl>

<p>The SeLu activation function is:</p>
<ul class="simple">
<li><p>if <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">&gt;</span> <span class="pre">0</span></code>: <code class="docutils literal notranslate"><span class="pre">selu(x)</span> <span class="pre">=</span> <span class="pre">scale</span> <span class="pre">*</span> <span class="pre">x</span></code></p></li>
<li><p>else: <code class="docutils literal notranslate"><span class="pre">selu(x)</span> <span class="pre">=</span> <span class="pre">scale</span> <span class="pre">*</span> <span class="pre">(alpha</span> <span class="pre">*</span>&#160; <span class="pre">(exp(x)</span> <span class="pre">-</span> <span class="pre">1))</span></code></p></li>
</ul>
<p>where <code class="docutils literal notranslate"><span class="pre">alpha</span> <span class="pre">=</span> <span class="pre">1.6732632423543772848170429916717</span></code> and <code class="docutils literal notranslate"><span class="pre">scale</span> <span class="pre">=</span> <span class="pre">1.0507009873554804934193349852946</span></code></p>
<p>Example:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Selu</span><span class="p">(</span><span class="n">l</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
</div>
<div class="section" id="exponential">
<h2>Exponential<a class="headerlink" href="#exponential" title="Permalink to this headline"></a></h2>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N4eddl11ExponentialE5layer6string">
<span id="_CPPv3N4eddl11ExponentialE5layer6string"></span><span id="_CPPv2N4eddl11ExponentialE5layer6string"></span><span id="eddl::Exponential__layer.string"></span><span class="target" id="namespaceeddl_1a75b9e3c63f8d30d8352998c0b7cb39e0"></span><span class="n"><span class="pre">layer</span></span><span class="w"> </span><span class="sig-prename descclassname"><span class="n"><span class="pre">eddl</span></span><span class="p"><span class="pre">::</span></span></span><span class="sig-name descname"><span class="n"><span class="pre">Exponential</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">layer</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">parent</span></span>, <span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">name</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="s"><span class="pre">&quot;&quot;</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N4eddl11ExponentialE5layer6string" title="Permalink to this definition"></a><br /></dt>
<dd><p>Applies the Exponential (base e) activation function to the given layer. </p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parent</strong> – Parent layer </p></li>
<li><p><strong>name</strong> – Name of the layer </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output of Exponential activation </p>
</dd>
</dl>
</dd></dl>

<p>The Exponential activation function is: <code class="docutils literal notranslate"><span class="pre">exp(x)</span></code></p>
<p>Example:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Exponential</span><span class="p">(</span><span class="n">l</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
</div>
<div class="section" id="softplus">
<h2>Softplus<a class="headerlink" href="#softplus" title="Permalink to this headline"></a></h2>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N4eddl8SoftplusE5layer6string">
<span id="_CPPv3N4eddl8SoftplusE5layer6string"></span><span id="_CPPv2N4eddl8SoftplusE5layer6string"></span><span id="eddl::Softplus__layer.string"></span><span class="target" id="namespaceeddl_1af42498d4447e23447656d64a571657d2"></span><span class="n"><span class="pre">layer</span></span><span class="w"> </span><span class="sig-prename descclassname"><span class="n"><span class="pre">eddl</span></span><span class="p"><span class="pre">::</span></span></span><span class="sig-name descname"><span class="n"><span class="pre">Softplus</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">layer</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">parent</span></span>, <span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">name</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="s"><span class="pre">&quot;&quot;</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N4eddl8SoftplusE5layer6string" title="Permalink to this definition"></a><br /></dt>
<dd><p>Applies the Softplus activation function to the given layer. </p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parent</strong> – Parent layer </p></li>
<li><p><strong>name</strong> – Name of the layer </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output of Exponential activation </p>
</dd>
</dl>
</dd></dl>

<p>The Softplus activation function is: <code class="docutils literal notranslate"><span class="pre">softplus(x)</span> <span class="pre">=</span> <span class="pre">log(1</span> <span class="pre">+</span> <span class="pre">exp(x))</span></code></p>
<p>Example:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Softplus</span><span class="p">(</span><span class="n">l</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
</div>
<div class="section" id="softsign">
<h2>Softsign<a class="headerlink" href="#softsign" title="Permalink to this headline"></a></h2>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N4eddl8SoftsignE5layer6string">
<span id="_CPPv3N4eddl8SoftsignE5layer6string"></span><span id="_CPPv2N4eddl8SoftsignE5layer6string"></span><span id="eddl::Softsign__layer.string"></span><span class="target" id="namespaceeddl_1ab6dc6e1d0fc0d788cab5c144c97ab037"></span><span class="n"><span class="pre">layer</span></span><span class="w"> </span><span class="sig-prename descclassname"><span class="n"><span class="pre">eddl</span></span><span class="p"><span class="pre">::</span></span></span><span class="sig-name descname"><span class="n"><span class="pre">Softsign</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">layer</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">parent</span></span>, <span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">name</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="s"><span class="pre">&quot;&quot;</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N4eddl8SoftsignE5layer6string" title="Permalink to this definition"></a><br /></dt>
<dd><p>Applies the Softsign activation function to the given layer. </p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parent</strong> – Parent layer </p></li>
<li><p><strong>name</strong> – Name of the layer </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output of Exponential activation </p>
</dd>
</dl>
</dd></dl>

<p>The Softsign activation function is: <code class="docutils literal notranslate"><span class="pre">softsign(x)</span> <span class="pre">=</span> <span class="pre">x</span> <span class="pre">/</span> <span class="pre">(1</span> <span class="pre">+</span> <span class="pre">abs(x))</span></code></p>
<p>Example:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Softsign</span><span class="p">(</span><span class="n">l</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
</div>
<div class="section" id="linear">
<h2>Linear<a class="headerlink" href="#linear" title="Permalink to this headline"></a></h2>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N4eddl6LinearE5layerf6string">
<span id="_CPPv3N4eddl6LinearE5layerf6string"></span><span id="_CPPv2N4eddl6LinearE5layerf6string"></span><span id="eddl::Linear__layer.float.string"></span><span class="target" id="namespaceeddl_1af6af7cce1216376d93feb8065e1d8ae1"></span><span class="n"><span class="pre">layer</span></span><span class="w"> </span><span class="sig-prename descclassname"><span class="n"><span class="pre">eddl</span></span><span class="p"><span class="pre">::</span></span></span><span class="sig-name descname"><span class="n"><span class="pre">Linear</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">layer</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">parent</span></span>, <span class="kt"><span class="pre">float</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">alpha</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="m"><span class="pre">1.0</span></span>, <span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">name</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="s"><span class="pre">&quot;&quot;</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N4eddl6LinearE5layerf6string" title="Permalink to this definition"></a><br /></dt>
<dd><p>Applies the Linear activation function to the given layer. </p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parent</strong> – Parent layer </p></li>
<li><p><strong>alpha</strong> – Linear coefficient </p></li>
<li><p><strong>name</strong> – Name of the layer </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output of Linear activation </p>
</dd>
</dl>
</dd></dl>

<p>The Linear activation function is: <code class="docutils literal notranslate"><span class="pre">linear(x)</span> <span class="pre">=</span> <span class="pre">alpha</span> <span class="pre">*</span> <span class="pre">x</span></code></p>
<p>Example:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Linear</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
</div>
<div class="section" id="tanh">
<h2>Tanh<a class="headerlink" href="#tanh" title="Permalink to this headline"></a></h2>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N4eddl4TanhE5layer6string">
<span id="_CPPv3N4eddl4TanhE5layer6string"></span><span id="_CPPv2N4eddl4TanhE5layer6string"></span><span id="eddl::Tanh__layer.string"></span><span class="target" id="namespaceeddl_1adb999cf367ad21b1aa322ec81b3bfdda"></span><span class="n"><span class="pre">layer</span></span><span class="w"> </span><span class="sig-prename descclassname"><span class="n"><span class="pre">eddl</span></span><span class="p"><span class="pre">::</span></span></span><span class="sig-name descname"><span class="n"><span class="pre">Tanh</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">layer</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">parent</span></span>, <span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">name</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="s"><span class="pre">&quot;&quot;</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N4eddl4TanhE5layer6string" title="Permalink to this definition"></a><br /></dt>
<dd><p>Applies the Hyperbolic tangent activation function to the given layer. </p>
<p><dl class="simple">
<dt><strong>See</strong></dt><dd><p><a class="reference external" href="https://en.wikipedia.org/wiki/Hyperbolic_function">https://en.wikipedia.org/wiki/Hyperbolic_function</a></p>
</dd>
</dl>
</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parent</strong> – Parent layer </p></li>
<li><p><strong>name</strong> – Name of the layer </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output of hyperbolic activation </p>
</dd>
</dl>
</dd></dl>

<p>The Tanh activation function is: <code class="docutils literal notranslate"><span class="pre">tanh(x)</span> <span class="pre">=</span> <span class="pre">sinh(x)/cosh(x)</span> <span class="pre">=</span> <span class="pre">((exp(x)</span> <span class="pre">-</span> <span class="pre">exp(-x))/(exp(x)</span> <span class="pre">+</span> <span class="pre">exp(-x)))</span></code></p>
<p>Example:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Tanh</span><span class="p">(</span><span class="n">l</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="auxiliar.html" class="btn btn-neutral float-left" title="Auxiliar Layers" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="data_augmentation.html" class="btn btn-neutral float-right" title="Data augmentation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, EDDL.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>